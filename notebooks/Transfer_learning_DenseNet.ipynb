{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import mlflow\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from collections import OrderedDict\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning with DenseNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "                                      ])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "                                    ])\n",
    "\n",
    "# setting up data loaders\n",
    "data_dir = os.path.join(os.pardir, 'data', 'Plant_leave_diseases_224')\n",
    "\n",
    "train_data = datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(os.path.join(data_dir, 'validation'), transform=test_transforms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Resnet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.densenet121(pretrained=True)\n",
    "\n",
    "# Freezing the paramiters of the layers we do not want to train\n",
    "for parameters in model.parameters():\n",
    "    parameters.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating Classification layer \n",
    "_inputs = model.classifier.in_features\n",
    "\n",
    "model.classifier = nn.Sequential(OrderedDict([\n",
    "    ('fc1', nn.Linear(_inputs, 500)),\n",
    "    ('relu', nn.ReLU()),\n",
    "    ('dropout', nn.Dropout(0.2)),\n",
    "    ('fc2', nn.Linear(500, 39)),\n",
    "    ('output', nn.LogSoftmax(dim=1))\n",
    "]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs \n",
    "config = {\n",
    "    'max_epochs': 200,\n",
    "    'learning_rate': 0.003,\n",
    "    'resolution': 32\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, validation_loader, config, n_epochs=10, stopping_treshold=None):\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        print('CUDA is available!  Training on GPU ...')\n",
    "        model.cuda()\n",
    "\n",
    "\n",
    "    # Loss and optimizer setup \n",
    "    criterion = nn.NLLLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "\n",
    "    # Setting minimum validation loss to inf\n",
    "    validation_loss_minimum = np.Inf \n",
    "    train_loss_history = []\n",
    "    validation_loss_history = []\n",
    "\n",
    "    for epoch in range(1, n_epochs +1):\n",
    "\n",
    "        training_loss = 0.0\n",
    "        validation_loss = 0.0\n",
    "\n",
    "        # Training loop\n",
    "        training_accuracies = []\n",
    "        for X, y in train_loader:\n",
    "            \n",
    "            # Moving data to gpu if using \n",
    "            if torch.cuda.is_available():\n",
    "                X, y = X.cuda(), y.cuda()\n",
    "            \n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(X)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, y)\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # update training loss\n",
    "            training_loss += loss.item()*X.size(0)\n",
    "\n",
    "            # calculating accuracy\n",
    "            ps = torch.exp(output)\n",
    "            top_p, top_class = ps.topk(1, dim=1)\n",
    "            equals = top_class == y.view(*top_class.shape)\n",
    "            training_accuracies.append(torch.mean(equals.type(torch.FloatTensor)).item())\n",
    "\n",
    "        # Validation Loop\n",
    "        with torch.no_grad():\n",
    "            accuracies = []\n",
    "            for X, y in validation_loader:\n",
    "\n",
    "                # Moving data to gpu if using \n",
    "                if torch.cuda.is_available():\n",
    "                    X, y = X.cuda(), y.cuda()\n",
    "                # forward pass: compute predicted outputs by passing inputs to the model\n",
    "                output = model(X)\n",
    "                # calculate the batch loss\n",
    "                loss = criterion(output, y)\n",
    "                # update validation loss\n",
    "                validation_loss += loss.item()*X.size(0)\n",
    "\n",
    "                # calculating accuracy\n",
    "                ps = torch.exp(output)\n",
    "                top_p, top_class = ps.topk(1, dim=1)\n",
    "                equals = top_class == y.view(*top_class.shape)\n",
    "                accuracies.append(torch.mean(equals.type(torch.FloatTensor)).item())\n",
    "                \n",
    "        # Mean loss \n",
    "        mean_training_loss = training_loss/len(train_loader.sampler)\n",
    "        mean_validation_loss = validation_loss/len(validation_loader.sampler)\n",
    "        mean_train_accuracy = sum(training_accuracies)/len(training_accuracies)\n",
    "        mean_accuracy = sum(accuracies)/len(accuracies)\n",
    "        train_loss_history.append(mean_training_loss)\n",
    "        validation_loss_history.append(mean_validation_loss)\n",
    "\n",
    "        # Printing epoch stats\n",
    "        print(f'Epoch: {epoch}/{n_epochs}, ' +\\\n",
    "              f'Training Loss: {mean_training_loss:.3f}, '+\\\n",
    "              f'Train accuracy {mean_train_accuracy:.3f} ' +\\\n",
    "              f'Validation Loss: {mean_validation_loss:.3f}, '+\\\n",
    "              f'Validation accuracy {mean_accuracy:.3f}')\n",
    "\n",
    "        # logging with mlflow \n",
    "        if mlflow.active_run():\n",
    "            mlflow.log_metric('loss', mean_training_loss, step=epoch)\n",
    "            mlflow.log_metric('accuracy', mean_train_accuracy, step=epoch)\n",
    "            mlflow.log_metric('validation_accuracy', mean_accuracy, step=epoch)\n",
    "            mlflow.log_metric('validation_loss', mean_validation_loss, step=epoch)\n",
    "\n",
    "        # Testing for early stopping\n",
    "        if stopping_treshold:\n",
    "            if mean_validation_loss < validation_loss_minimum:\n",
    "                validation_loss_minimum = mean_validation_loss\n",
    "            elif len([v for v in validation_loss_history[-stopping_treshold:] if v >= validation_loss_minimum]) >= stopping_treshold:\n",
    "                print(f\"Stopping early at epoch: {epoch}/{n_epochs}\")\n",
    "                break\n",
    "        \n",
    "\n",
    "    return train_loss_history, validation_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ngrec\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\plant-leaf-diseases-identification-CBiGMIHu-py3.8\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/200, Training Loss: 0.921, Train accuracy 0.730 Validation Loss: 0.346, Validation accuracy 0.885\n",
      "Epoch: 2/200, Training Loss: 0.644, Train accuracy 0.800 Validation Loss: 0.330, Validation accuracy 0.888\n",
      "Epoch: 3/200, Training Loss: 0.604, Train accuracy 0.814 Validation Loss: 0.291, Validation accuracy 0.902\n",
      "Epoch: 4/200, Training Loss: 0.590, Train accuracy 0.817 Validation Loss: 0.287, Validation accuracy 0.906\n",
      "Epoch: 5/200, Training Loss: 0.570, Train accuracy 0.826 Validation Loss: 0.282, Validation accuracy 0.908\n",
      "Epoch: 6/200, Training Loss: 0.554, Train accuracy 0.829 Validation Loss: 0.262, Validation accuracy 0.914\n",
      "Epoch: 7/200, Training Loss: 0.560, Train accuracy 0.829 Validation Loss: 0.266, Validation accuracy 0.912\n",
      "Epoch: 8/200, Training Loss: 0.536, Train accuracy 0.834 Validation Loss: 0.248, Validation accuracy 0.922\n",
      "Epoch: 9/200, Training Loss: 0.551, Train accuracy 0.833 Validation Loss: 0.258, Validation accuracy 0.917\n",
      "Epoch: 10/200, Training Loss: 0.535, Train accuracy 0.837 Validation Loss: 0.264, Validation accuracy 0.916\n",
      "Epoch: 11/200, Training Loss: 0.535, Train accuracy 0.839 Validation Loss: 0.246, Validation accuracy 0.920\n",
      "Epoch: 12/200, Training Loss: 0.523, Train accuracy 0.840 Validation Loss: 0.255, Validation accuracy 0.916\n",
      "Epoch: 13/200, Training Loss: 0.511, Train accuracy 0.846 Validation Loss: 0.220, Validation accuracy 0.928\n",
      "Epoch: 14/200, Training Loss: 0.511, Train accuracy 0.847 Validation Loss: 0.252, Validation accuracy 0.921\n",
      "Epoch: 15/200, Training Loss: 0.509, Train accuracy 0.847 Validation Loss: 0.290, Validation accuracy 0.909\n",
      "Stopping early at epoch: 15/200\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=True)\n",
    "\n",
    "mlflow.set_experiment(\"Plant Leaf Disease\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param('framework', 'pytorch')\n",
    "    mlflow.log_param('data_split', '90/10')\n",
    "    mlflow.log_param('type', 'DenseNet121')\n",
    "    mlflow.log_params(config)\n",
    "    train(model, train_loader, validation_loader, config, n_epochs=config['max_epochs'], stopping_treshold=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d53c06ab4573055b295bcdfb3b25bc2da21e5ae576a05184a9c53fc2168185ab"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('plant-leaf-diseases-identification-CBiGMIHu-py3.8': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
