{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import mlflow\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from collections import OrderedDict\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning with Resnet 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Resnet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = models.resnet50(pretrained=True)\n",
    "\n",
    "# Freezing the paramiters of the layers we do not want to train\n",
    "for parameters in mdl.parameters():\n",
    "    parameters.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating Classification layer \n",
    "_inputs = mdl.fc.in_features\n",
    "\n",
    "mdl.fc = nn.Sequential(OrderedDict([\n",
    "    ('fc1', nn.Linear(_inputs, 500)),\n",
    "    ('relu', nn.ReLU()),\n",
    "    ('dropout', nn.Dropout(0.2)),\n",
    "    ('fc2', nn.Linear(500, 39)),\n",
    "    ('output', nn.LogSoftmax(dim=1))\n",
    "]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, validation_loader, config, n_epochs=10, stopping_treshold=None):\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        print('CUDA is available!  Training on GPU ...')\n",
    "        model.cuda()\n",
    "\n",
    "\n",
    "    # Loss and optimizer setup \n",
    "    criterion = nn.NLLLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "\n",
    "    # Setting minimum validation loss to inf\n",
    "    validation_loss_minimum = np.Inf \n",
    "    train_loss_history = []\n",
    "    validation_loss_history = []\n",
    "\n",
    "    for epoch in range(1, n_epochs +1):\n",
    "\n",
    "        training_loss = 0.0\n",
    "        validation_loss = 0.0\n",
    "\n",
    "        # Training loop\n",
    "        training_accuracies = []\n",
    "        for X, y in train_loader:\n",
    "            \n",
    "            # Moving data to gpu if using \n",
    "            if torch.cuda.is_available():\n",
    "                X, y = X.cuda(), y.cuda()\n",
    "            \n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(X)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, y)\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # update training loss\n",
    "            training_loss += loss.item()*X.size(0)\n",
    "\n",
    "            # calculating accuracy\n",
    "            ps = torch.exp(output)\n",
    "            top_p, top_class = ps.topk(1, dim=1)\n",
    "            equals = top_class == y.view(*top_class.shape)\n",
    "            training_accuracies.append(torch.mean(equals.type(torch.FloatTensor)).item())\n",
    "\n",
    "        # Validation Loop\n",
    "        with torch.no_grad():\n",
    "            accuracies = []\n",
    "            for X, y in validation_loader:\n",
    "\n",
    "                # Moving data to gpu if using \n",
    "                if torch.cuda.is_available():\n",
    "                    X, y = X.cuda(), y.cuda()\n",
    "                # forward pass: compute predicted outputs by passing inputs to the model\n",
    "                output = model(X)\n",
    "                # calculate the batch loss\n",
    "                loss = criterion(output, y)\n",
    "                # update validation loss\n",
    "                validation_loss += loss.item()*X.size(0)\n",
    "\n",
    "                # calculating accuracy\n",
    "                ps = torch.exp(output)\n",
    "                top_p, top_class = ps.topk(1, dim=1)\n",
    "                equals = top_class == y.view(*top_class.shape)\n",
    "                accuracies.append(torch.mean(equals.type(torch.FloatTensor)).item())\n",
    "                \n",
    "        # Mean loss \n",
    "        mean_training_loss = training_loss/len(train_loader.sampler)\n",
    "        mean_validation_loss = validation_loss/len(validation_loader.sampler)\n",
    "        mean_train_accuracy = sum(training_accuracies)/len(training_accuracies)\n",
    "        mean_accuracy = sum(accuracies)/len(accuracies)\n",
    "        train_loss_history.append(mean_training_loss)\n",
    "        validation_loss_history.append(mean_validation_loss)\n",
    "\n",
    "        # Printing epoch stats\n",
    "        print(f'Epoch: {epoch}/{n_epochs}, ' +\\\n",
    "              f'Training Loss: {mean_training_loss:.3f}, '+\\\n",
    "              f'Train accuracy {mean_train_accuracy:.3f} ' +\\\n",
    "              f'Validation Loss: {mean_validation_loss:.3f}, '+\\\n",
    "              f'Validation accuracy {mean_accuracy:.3f}')\n",
    "\n",
    "        # logging with mlflow \n",
    "        if mlflow.active_run():\n",
    "            mlflow.log_metric('loss', mean_training_loss, step=epoch)\n",
    "            mlflow.log_metric('accuracy', mean_train_accuracy, step=epoch)\n",
    "            mlflow.log_metric('validation_accuracy', mean_accuracy, step=epoch)\n",
    "            mlflow.log_metric('validation_loss', mean_validation_loss, step=epoch)\n",
    "\n",
    "        # Testing for early stopping\n",
    "        if stopping_treshold:\n",
    "            if mean_validation_loss < validation_loss_minimum:\n",
    "                validation_loss_minimum = mean_validation_loss\n",
    "            elif len([v for v in validation_loss_history[-stopping_treshold:] if v >= validation_loss_minimum]) >= stopping_treshold:\n",
    "                print(f\"Stopping early at epoch: {epoch}/{n_epochs}\")\n",
    "                break\n",
    "        \n",
    "\n",
    "    return train_loss_history, validation_loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training - 32x32 resolution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(32),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "                                      ])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(34),\n",
    "                                      transforms.CenterCrop(32),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "                                    ])\n",
    "# setting up data loaders\n",
    "data_dir = os.path.join(os.pardir, 'data', 'Plant_leave_diseases_32')\n",
    "\n",
    "train_data = datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(os.path.join(data_dir, 'validation'), transform=test_transforms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs \n",
    "config = {\n",
    "    'max_epochs': 200,\n",
    "    'learning_rate': 0.002,\n",
    "    'resolution': 32\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n",
      "Epoch: 1/200, Training Loss: 2.526, Train accuracy 0.325 Validation Loss: 2.193, Validation accuracy 0.394\n",
      "Epoch: 2/200, Training Loss: 2.288, Train accuracy 0.375 Validation Loss: 2.070, Validation accuracy 0.428\n",
      "Epoch: 3/200, Training Loss: 2.235, Train accuracy 0.387 Validation Loss: 2.003, Validation accuracy 0.439\n",
      "Epoch: 4/200, Training Loss: 2.207, Train accuracy 0.393 Validation Loss: 1.987, Validation accuracy 0.437\n",
      "Epoch: 5/200, Training Loss: 2.173, Train accuracy 0.399 Validation Loss: 1.993, Validation accuracy 0.450\n",
      "Epoch: 6/200, Training Loss: 2.152, Train accuracy 0.405 Validation Loss: 1.958, Validation accuracy 0.445\n",
      "Epoch: 7/200, Training Loss: 2.139, Train accuracy 0.410 Validation Loss: 1.940, Validation accuracy 0.451\n",
      "Epoch: 8/200, Training Loss: 2.128, Train accuracy 0.410 Validation Loss: 1.927, Validation accuracy 0.456\n",
      "Epoch: 9/200, Training Loss: 2.115, Train accuracy 0.414 Validation Loss: 1.897, Validation accuracy 0.462\n",
      "Epoch: 10/200, Training Loss: 2.107, Train accuracy 0.417 Validation Loss: 1.934, Validation accuracy 0.450\n",
      "Epoch: 11/200, Training Loss: 2.100, Train accuracy 0.420 Validation Loss: 1.898, Validation accuracy 0.461\n",
      "Epoch: 12/200, Training Loss: 2.099, Train accuracy 0.418 Validation Loss: 1.856, Validation accuracy 0.477\n",
      "Epoch: 13/200, Training Loss: 2.082, Train accuracy 0.421 Validation Loss: 1.873, Validation accuracy 0.466\n",
      "Epoch: 14/200, Training Loss: 2.081, Train accuracy 0.427 Validation Loss: 1.868, Validation accuracy 0.472\n",
      "Epoch: 15/200, Training Loss: 2.071, Train accuracy 0.425 Validation Loss: 1.831, Validation accuracy 0.477\n",
      "Epoch: 16/200, Training Loss: 2.070, Train accuracy 0.425 Validation Loss: 1.866, Validation accuracy 0.474\n",
      "Stopping early at epoch: 16/200\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=True)\n",
    "\n",
    "mlflow.set_experiment(\"Plant Leaf Disease\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param('framework', 'pytorch')\n",
    "    mlflow.log_param('data_split', '90/10')\n",
    "    mlflow.log_param('type', 'Resnet50')\n",
    "    mlflow.log_params(config)\n",
    "    train(mdl, train_loader, validation_loader, config, n_epochs=config['max_epochs'], stopping_treshold=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training 224X224 resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "                                      ])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "                                    ])\n",
    "\n",
    "# setting up data loaders\n",
    "data_dir = os.path.join(os.pardir, 'data', 'Plant_leave_diseases_224')\n",
    "\n",
    "train_data = datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(os.path.join(data_dir, 'validation'), transform=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = models.resnet50(pretrained=True)\n",
    "\n",
    "# Freezing the paramiters of the layers we do not want to train\n",
    "for parameters in mdl.parameters():\n",
    "    parameters.requires_grad = False\n",
    "\n",
    "# Updating Classification layer \n",
    "_inputs = mdl.fc.in_features\n",
    "\n",
    "mdl.fc = nn.Sequential(OrderedDict([\n",
    "    ('fc1', nn.Linear(_inputs, 500)),\n",
    "    ('relu', nn.ReLU()),\n",
    "    ('dropout', nn.Dropout(0.2)),\n",
    "    ('fc2', nn.Linear(500, 39)),\n",
    "    ('output', nn.LogSoftmax(dim=1))\n",
    "]))\n",
    "\n",
    "# Configs \n",
    "config = {\n",
    "    'max_epochs': 200,\n",
    "    'learning_rate': 0.002,\n",
    "    'resolution': 224\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n",
      "Epoch: 1/200, Training Loss: 0.991, Train accuracy 0.708 Validation Loss: 0.536, Validation accuracy 0.827\n",
      "Epoch: 2/200, Training Loss: 0.697, Train accuracy 0.785 Validation Loss: 0.372, Validation accuracy 0.877\n",
      "Epoch: 3/200, Training Loss: 0.653, Train accuracy 0.797 Validation Loss: 0.355, Validation accuracy 0.879\n",
      "Epoch: 4/200, Training Loss: 0.625, Train accuracy 0.806 Validation Loss: 0.329, Validation accuracy 0.890\n",
      "Epoch: 5/200, Training Loss: 0.606, Train accuracy 0.813 Validation Loss: 0.326, Validation accuracy 0.891\n",
      "Epoch: 6/200, Training Loss: 0.594, Train accuracy 0.817 Validation Loss: 0.286, Validation accuracy 0.904\n",
      "Epoch: 7/200, Training Loss: 0.579, Train accuracy 0.822 Validation Loss: 0.301, Validation accuracy 0.899\n",
      "Epoch: 8/200, Training Loss: 0.566, Train accuracy 0.825 Validation Loss: 0.316, Validation accuracy 0.891\n",
      "Epoch: 9/200, Training Loss: 0.558, Train accuracy 0.827 Validation Loss: 0.285, Validation accuracy 0.896\n",
      "Epoch: 10/200, Training Loss: 0.549, Train accuracy 0.830 Validation Loss: 0.276, Validation accuracy 0.910\n",
      "Epoch: 11/200, Training Loss: 0.533, Train accuracy 0.835 Validation Loss: 0.279, Validation accuracy 0.908\n",
      "Epoch: 12/200, Training Loss: 0.535, Train accuracy 0.836 Validation Loss: 0.282, Validation accuracy 0.910\n",
      "Epoch: 13/200, Training Loss: 0.515, Train accuracy 0.839 Validation Loss: 0.265, Validation accuracy 0.915\n",
      "Epoch: 14/200, Training Loss: 0.525, Train accuracy 0.839 Validation Loss: 0.290, Validation accuracy 0.908\n",
      "Epoch: 15/200, Training Loss: 0.516, Train accuracy 0.842 Validation Loss: 0.260, Validation accuracy 0.910\n",
      "Epoch: 16/200, Training Loss: 0.510, Train accuracy 0.844 Validation Loss: 0.280, Validation accuracy 0.908\n",
      "Stopping early at epoch: 16/200\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=True)\n",
    "\n",
    "mlflow.set_experiment(\"Plant Leaf Disease\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param('framework', 'pytorch')\n",
    "    mlflow.log_param('data_split', '90/10')\n",
    "    mlflow.log_param('type', 'Resnet50')\n",
    "    mlflow.log_params(config)\n",
    "    train(mdl, train_loader, validation_loader, config, n_epochs=config['max_epochs'], stopping_treshold=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d53c06ab4573055b295bcdfb3b25bc2da21e5ae576a05184a9c53fc2168185ab"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('plant-leaf-diseases-identification-CBiGMIHu-py3.8': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
