{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29ee38e8",
   "metadata": {},
   "source": [
    "# Implementation of 9-layer CNN (pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5b2250c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import mlflow\n",
    "import time\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dbb6cc",
   "metadata": {},
   "source": [
    "## Data loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5072b44",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d69b9a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(128),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "                                      ])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(129),\n",
    "                                      transforms.CenterCrop(128),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "                                    ])\n",
    "\n",
    "# setting up data loaders\n",
    "data_dir = os.path.join(os.pardir, 'data', 'Plant_leave_diseases_224')\n",
    "\n",
    "train_data = datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(os.path.join(data_dir, 'validation'), transform=test_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7169ceb9",
   "metadata": {},
   "source": [
    "## Defining  9-layer CNN (geetharamani et.al., 2019):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ab62307d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NineLayerNet(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (poolconv1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (poolconv2): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (conv3): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=6272, out_features=1568, bias=True)\n",
       "  (fc2): Linear(in_features=1568, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=39, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NineLayerNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3)\n",
    "        self.poolconv1 = nn.Conv2d(32, 16, 1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 16, 3)\n",
    "        self.poolconv2 = nn.Conv2d(16, 8, 1)\n",
    "        self.conv3 = nn.Conv2d(8, 8, 3)\n",
    "        self.fc1 = nn.Linear(8 * 28 * 28, 1568)\n",
    "        self.fc2 = nn.Linear(1568, 128)\n",
    "        self.fc3 = nn.Linear(128, 39)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.poolconv1(self.pool(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.poolconv2(self.pool(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.log_softmax(self.fc3(x), dim=1)\n",
    "        return x\n",
    "\n",
    "model = NineLayerNet()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bbe31c",
   "metadata": {},
   "source": [
    "## Defining Training function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "874f1fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, validation_loader, config, n_epochs=10, stopping_treshold=None):\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        print('CUDA is available!  Training on GPU ...')\n",
    "        model.cuda()\n",
    "\n",
    "\n",
    "    # Loss and optimizer setup \n",
    "    criterion = nn.NLLLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "\n",
    "    # Setting minimum validation loss to inf\n",
    "    validation_loss_minimum = np.Inf \n",
    "    train_loss_history = []\n",
    "    validation_loss_history = []\n",
    "\n",
    "    for epoch in range(1, n_epochs +1):\n",
    "\n",
    "        t0 = time.time()\n",
    "        training_loss = 0.0\n",
    "        validation_loss = 0.0\n",
    "\n",
    "        # Training loop\n",
    "        training_accuracies = []\n",
    "        for X, y in train_loader:\n",
    "            \n",
    "            # Moving data to gpu if using \n",
    "            if torch.cuda.is_available():\n",
    "                X, y = X.cuda(), y.cuda()\n",
    "            \n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(X)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, y)\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # update training loss\n",
    "            training_loss += loss.item()*X.size(0)\n",
    "\n",
    "            # calculating accuracy\n",
    "            ps = torch.exp(output)\n",
    "            top_p, top_class = ps.topk(1, dim=1)\n",
    "            equals = top_class == y.view(*top_class.shape)\n",
    "            training_accuracies.append(torch.mean(equals.type(torch.FloatTensor)).item())\n",
    "\n",
    "        # Validation Loop\n",
    "        with torch.no_grad():\n",
    "            accuracies = []\n",
    "            for X, y in validation_loader:\n",
    "\n",
    "                # Moving data to gpu if using \n",
    "                if torch.cuda.is_available():\n",
    "                    X, y = X.cuda(), y.cuda()\n",
    "                # forward pass: compute predicted outputs by passing inputs to the model\n",
    "                output = model(X)\n",
    "                # calculate the batch loss\n",
    "                loss = criterion(output, y)\n",
    "                # update validation loss\n",
    "                validation_loss += loss.item()*X.size(0)\n",
    "\n",
    "                # calculating accuracy\n",
    "                ps = torch.exp(output)\n",
    "                top_p, top_class = ps.topk(1, dim=1)\n",
    "                equals = top_class == y.view(*top_class.shape)\n",
    "                accuracies.append(torch.mean(equals.type(torch.FloatTensor)).item())\n",
    "                \n",
    "        # Mean loss \n",
    "        mean_training_loss = training_loss/len(train_loader.sampler)\n",
    "        mean_validation_loss = validation_loss/len(validation_loader.sampler)\n",
    "        mean_train_accuracy = sum(training_accuracies)/len(training_accuracies)\n",
    "        mean_accuracy = sum(accuracies)/len(accuracies)\n",
    "        train_loss_history.append(mean_training_loss)\n",
    "        validation_loss_history.append(mean_validation_loss)\n",
    "        t_d0 = time.time() - t0\n",
    "\n",
    "        # Printing epoch stats\n",
    "        print(f'Epoch: {epoch}/{n_epochs}, ' +\\\n",
    "              f'Training Loss: {mean_training_loss:.3f}, '+\\\n",
    "              f'Train accuracy {mean_train_accuracy:.3f} ' +\\\n",
    "              f'Validation Loss: {mean_validation_loss:.3f}, '+\\\n",
    "              f'Validation accuracy {mean_accuracy:.3f},' +\\\n",
    "              f'Epoch runtime: {t_d0}')  \n",
    "\n",
    "        # logging with mlflow \n",
    "        if mlflow.active_run():\n",
    "            mlflow.log_metric('loss', mean_training_loss, step=epoch)\n",
    "            mlflow.log_metric('accuracy', mean_train_accuracy, step=epoch)\n",
    "            mlflow.log_metric('validation_accuracy', mean_accuracy, step=epoch)\n",
    "            mlflow.log_metric('validation_loss', mean_validation_loss, step=epoch)\n",
    "\n",
    "        # Testing for early stopping\n",
    "        if stopping_treshold:\n",
    "            if mean_validation_loss < validation_loss_minimum:\n",
    "                validation_loss_minimum = mean_validation_loss\n",
    "                print('New minimum validation loss (saving model)')\n",
    "                save_pth = os.path.join('models',f'{config[\"name\"]}.pt')\n",
    "                torch.save(model.state_dict(), save_pth)\n",
    "            elif len([v for v in validation_loss_history[-stopping_treshold:] if v > validation_loss_minimum]) >= stopping_treshold:\n",
    "                print(f\"Stopping early at epoch: {epoch}/{n_epochs}\")\n",
    "                break\n",
    "        \n",
    "\n",
    "    return train_loss_history, validation_loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51af43ca",
   "metadata": {},
   "source": [
    "### Train config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7d59977a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs \n",
    "config = {\n",
    "    'max_epochs': 200,\n",
    "    'learning_rate': 0.003,\n",
    "    'resolution': 128,\n",
    "    'name': 'CNN_9layer_pytorch'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb41934",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3e05e847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n",
      "Epoch: 1/200, Training Loss: 2.630, Train accuracy 0.285 Validation Loss: 1.721, Validation accuracy 0.483,Epoch runtime: 122.43713927268982\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 2/200, Training Loss: 1.738, Train accuracy 0.490 Validation Loss: 1.263, Validation accuracy 0.601,Epoch runtime: 169.2669279575348\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 3/200, Training Loss: 1.409, Train accuracy 0.578 Validation Loss: 1.063, Validation accuracy 0.665,Epoch runtime: 173.15866374969482\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 4/200, Training Loss: 1.261, Train accuracy 0.621 Validation Loss: 0.823, Validation accuracy 0.731,Epoch runtime: 152.771555185318\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 5/200, Training Loss: 1.162, Train accuracy 0.650 Validation Loss: 0.734, Validation accuracy 0.772,Epoch runtime: 162.3954164981842\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 6/200, Training Loss: 1.076, Train accuracy 0.673 Validation Loss: 0.710, Validation accuracy 0.773,Epoch runtime: 228.0585310459137\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 7/200, Training Loss: 1.025, Train accuracy 0.688 Validation Loss: 0.724, Validation accuracy 0.776,Epoch runtime: 276.51936435699463\n",
      "Epoch: 8/200, Training Loss: 0.983, Train accuracy 0.700 Validation Loss: 0.581, Validation accuracy 0.821,Epoch runtime: 158.96090292930603\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 9/200, Training Loss: 0.944, Train accuracy 0.713 Validation Loss: 0.591, Validation accuracy 0.815,Epoch runtime: 223.80241703987122\n",
      "Epoch: 10/200, Training Loss: 0.901, Train accuracy 0.725 Validation Loss: 0.584, Validation accuracy 0.816,Epoch runtime: 238.6872160434723\n",
      "Epoch: 11/200, Training Loss: 0.885, Train accuracy 0.730 Validation Loss: 0.584, Validation accuracy 0.810,Epoch runtime: 214.49899458885193\n",
      "Epoch: 12/200, Training Loss: 0.869, Train accuracy 0.735 Validation Loss: 0.539, Validation accuracy 0.832,Epoch runtime: 233.44717955589294\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 13/200, Training Loss: 0.843, Train accuracy 0.741 Validation Loss: 0.623, Validation accuracy 0.807,Epoch runtime: 235.5544936656952\n",
      "Epoch: 14/200, Training Loss: 0.833, Train accuracy 0.746 Validation Loss: 0.441, Validation accuracy 0.860,Epoch runtime: 191.73256421089172\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 15/200, Training Loss: 0.808, Train accuracy 0.755 Validation Loss: 0.535, Validation accuracy 0.827,Epoch runtime: 177.94885778427124\n",
      "Epoch: 16/200, Training Loss: 0.802, Train accuracy 0.755 Validation Loss: 0.554, Validation accuracy 0.820,Epoch runtime: 173.1966323852539\n",
      "Epoch: 17/200, Training Loss: 0.817, Train accuracy 0.751 Validation Loss: 0.548, Validation accuracy 0.825,Epoch runtime: 177.82113242149353\n",
      "Epoch: 18/200, Training Loss: 0.781, Train accuracy 0.761 Validation Loss: 0.555, Validation accuracy 0.825,Epoch runtime: 184.11550211906433\n",
      "Epoch: 19/200, Training Loss: 0.775, Train accuracy 0.763 Validation Loss: 0.495, Validation accuracy 0.838,Epoch runtime: 231.06070351600647\n",
      "Epoch: 20/200, Training Loss: 0.784, Train accuracy 0.762 Validation Loss: 0.471, Validation accuracy 0.851,Epoch runtime: 173.74059963226318\n",
      "Epoch: 21/200, Training Loss: 0.767, Train accuracy 0.765 Validation Loss: 0.503, Validation accuracy 0.842,Epoch runtime: 173.60787987709045\n",
      "Epoch: 22/200, Training Loss: 0.764, Train accuracy 0.767 Validation Loss: 0.423, Validation accuracy 0.867,Epoch runtime: 184.91387248039246\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 23/200, Training Loss: 0.758, Train accuracy 0.768 Validation Loss: 0.446, Validation accuracy 0.865,Epoch runtime: 206.16897249221802\n",
      "Epoch: 24/200, Training Loss: 0.753, Train accuracy 0.769 Validation Loss: 0.411, Validation accuracy 0.868,Epoch runtime: 175.73016786575317\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 25/200, Training Loss: 0.754, Train accuracy 0.770 Validation Loss: 0.433, Validation accuracy 0.860,Epoch runtime: 186.53615379333496\n",
      "Epoch: 26/200, Training Loss: 0.736, Train accuracy 0.776 Validation Loss: 0.392, Validation accuracy 0.873,Epoch runtime: 328.9201431274414\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 27/200, Training Loss: 0.719, Train accuracy 0.779 Validation Loss: 0.416, Validation accuracy 0.867,Epoch runtime: 1092.8834958076477\n",
      "Epoch: 28/200, Training Loss: 0.731, Train accuracy 0.778 Validation Loss: 0.563, Validation accuracy 0.824,Epoch runtime: 537.3363194465637\n",
      "Epoch: 29/200, Training Loss: 0.738, Train accuracy 0.777 Validation Loss: 0.421, Validation accuracy 0.866,Epoch runtime: 323.5755205154419\n",
      "Epoch: 30/200, Training Loss: 0.721, Train accuracy 0.781 Validation Loss: 0.533, Validation accuracy 0.836,Epoch runtime: 317.5021016597748\n",
      "Epoch: 31/200, Training Loss: 0.718, Train accuracy 0.782 Validation Loss: 0.489, Validation accuracy 0.851,Epoch runtime: 315.63757038116455\n",
      "Epoch: 32/200, Training Loss: 0.741, Train accuracy 0.775 Validation Loss: 0.469, Validation accuracy 0.851,Epoch runtime: 316.61344838142395\n",
      "Epoch: 33/200, Training Loss: 0.715, Train accuracy 0.781 Validation Loss: 0.397, Validation accuracy 0.872,Epoch runtime: 314.8896131515503\n",
      "Epoch: 34/200, Training Loss: 0.705, Train accuracy 0.785 Validation Loss: 0.432, Validation accuracy 0.868,Epoch runtime: 317.9853096008301\n",
      "Epoch: 35/200, Training Loss: 0.719, Train accuracy 0.783 Validation Loss: 0.469, Validation accuracy 0.859,Epoch runtime: 311.0364329814911\n",
      "Epoch: 36/200, Training Loss: 0.717, Train accuracy 0.782 Validation Loss: 0.397, Validation accuracy 0.872,Epoch runtime: 310.49989080429077\n",
      "Epoch: 37/200, Training Loss: 0.710, Train accuracy 0.784 Validation Loss: 0.373, Validation accuracy 0.881,Epoch runtime: 312.732905626297\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 38/200, Training Loss: 0.709, Train accuracy 0.786 Validation Loss: 0.382, Validation accuracy 0.880,Epoch runtime: 313.2604646682739\n",
      "Epoch: 39/200, Training Loss: 0.691, Train accuracy 0.790 Validation Loss: 0.402, Validation accuracy 0.874,Epoch runtime: 313.65295124053955\n",
      "Epoch: 40/200, Training Loss: 0.684, Train accuracy 0.792 Validation Loss: 0.377, Validation accuracy 0.882,Epoch runtime: 312.001309633255\n",
      "Epoch: 41/200, Training Loss: 0.693, Train accuracy 0.790 Validation Loss: 0.408, Validation accuracy 0.875,Epoch runtime: 312.5029442310333\n",
      "Epoch: 42/200, Training Loss: 0.691, Train accuracy 0.791 Validation Loss: 0.495, Validation accuracy 0.852,Epoch runtime: 314.53204679489136\n",
      "Epoch: 43/200, Training Loss: 0.708, Train accuracy 0.786 Validation Loss: 0.523, Validation accuracy 0.843,Epoch runtime: 314.92049741744995\n",
      "Epoch: 44/200, Training Loss: 0.706, Train accuracy 0.786 Validation Loss: 0.419, Validation accuracy 0.870,Epoch runtime: 313.4818480014801\n",
      "Epoch: 45/200, Training Loss: 0.688, Train accuracy 0.790 Validation Loss: 0.468, Validation accuracy 0.858,Epoch runtime: 313.5721161365509\n",
      "Epoch: 46/200, Training Loss: 0.676, Train accuracy 0.794 Validation Loss: 0.412, Validation accuracy 0.871,Epoch runtime: 311.4288694858551\n",
      "Epoch: 47/200, Training Loss: 0.690, Train accuracy 0.791 Validation Loss: 0.429, Validation accuracy 0.867,Epoch runtime: 311.4058926105499\n",
      "Epoch: 48/200, Training Loss: 0.696, Train accuracy 0.790 Validation Loss: 0.400, Validation accuracy 0.876,Epoch runtime: 312.642121553421\n",
      "Epoch: 49/200, Training Loss: 0.669, Train accuracy 0.797 Validation Loss: 0.459, Validation accuracy 0.860,Epoch runtime: 312.89144349098206\n",
      "Epoch: 50/200, Training Loss: 0.668, Train accuracy 0.795 Validation Loss: 0.367, Validation accuracy 0.884,Epoch runtime: 311.01245379447937\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 51/200, Training Loss: 0.687, Train accuracy 0.793 Validation Loss: 0.355, Validation accuracy 0.892,Epoch runtime: 312.2815852165222\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 52/200, Training Loss: 0.673, Train accuracy 0.795 Validation Loss: 0.569, Validation accuracy 0.823,Epoch runtime: 313.2165718078613\n",
      "Epoch: 53/200, Training Loss: 0.679, Train accuracy 0.795 Validation Loss: 0.466, Validation accuracy 0.857,Epoch runtime: 312.3413767814636\n",
      "Epoch: 54/200, Training Loss: 0.672, Train accuracy 0.797 Validation Loss: 0.373, Validation accuracy 0.885,Epoch runtime: 313.1896159648895\n",
      "Epoch: 55/200, Training Loss: 0.686, Train accuracy 0.792 Validation Loss: 0.359, Validation accuracy 0.883,Epoch runtime: 316.0464696884155\n",
      "Epoch: 56/200, Training Loss: 0.669, Train accuracy 0.797 Validation Loss: 0.352, Validation accuracy 0.892,Epoch runtime: 315.52985167503357\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 57/200, Training Loss: 0.683, Train accuracy 0.794 Validation Loss: 0.384, Validation accuracy 0.879,Epoch runtime: 313.8657946586609\n",
      "Epoch: 58/200, Training Loss: 0.682, Train accuracy 0.794 Validation Loss: 0.387, Validation accuracy 0.875,Epoch runtime: 314.7395043373108\n",
      "Epoch: 59/200, Training Loss: 0.684, Train accuracy 0.795 Validation Loss: 0.461, Validation accuracy 0.859,Epoch runtime: 314.06031131744385\n",
      "Epoch: 60/200, Training Loss: 0.674, Train accuracy 0.796 Validation Loss: 0.387, Validation accuracy 0.882,Epoch runtime: 312.9881727695465\n",
      "Epoch: 61/200, Training Loss: 0.659, Train accuracy 0.798 Validation Loss: 0.383, Validation accuracy 0.881,Epoch runtime: 310.83096385002136\n",
      "Epoch: 62/200, Training Loss: 0.666, Train accuracy 0.799 Validation Loss: 0.378, Validation accuracy 0.884,Epoch runtime: 312.03024435043335\n",
      "Epoch: 63/200, Training Loss: 0.676, Train accuracy 0.796 Validation Loss: 0.610, Validation accuracy 0.822,Epoch runtime: 311.6408040523529\n",
      "Epoch: 64/200, Training Loss: 0.661, Train accuracy 0.800 Validation Loss: 0.350, Validation accuracy 0.889,Epoch runtime: 312.2611653804779\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 65/200, Training Loss: 0.673, Train accuracy 0.796 Validation Loss: 0.340, Validation accuracy 0.895,Epoch runtime: 314.2158782482147\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 66/200, Training Loss: 0.661, Train accuracy 0.799 Validation Loss: 0.363, Validation accuracy 0.890,Epoch runtime: 313.96153950691223\n",
      "Epoch: 67/200, Training Loss: 0.661, Train accuracy 0.800 Validation Loss: 0.390, Validation accuracy 0.878,Epoch runtime: 314.3106179237366\n",
      "Epoch: 68/200, Training Loss: 0.674, Train accuracy 0.798 Validation Loss: 0.410, Validation accuracy 0.875,Epoch runtime: 314.7369725704193\n",
      "Epoch: 69/200, Training Loss: 0.660, Train accuracy 0.803 Validation Loss: 0.412, Validation accuracy 0.871,Epoch runtime: 314.0632674694061\n",
      "Epoch: 70/200, Training Loss: 0.664, Train accuracy 0.801 Validation Loss: 0.382, Validation accuracy 0.886,Epoch runtime: 312.6530818939209\n",
      "Epoch: 71/200, Training Loss: 0.664, Train accuracy 0.801 Validation Loss: 0.578, Validation accuracy 0.833,Epoch runtime: 311.7514855861664\n",
      "Epoch: 72/200, Training Loss: 0.679, Train accuracy 0.796 Validation Loss: 0.408, Validation accuracy 0.876,Epoch runtime: 313.3397068977356\n",
      "Epoch: 73/200, Training Loss: 0.656, Train accuracy 0.804 Validation Loss: 0.379, Validation accuracy 0.882,Epoch runtime: 313.8533878326416\n",
      "Epoch: 74/200, Training Loss: 0.667, Train accuracy 0.798 Validation Loss: 0.348, Validation accuracy 0.895,Epoch runtime: 312.0282862186432\n",
      "Epoch: 75/200, Training Loss: 0.656, Train accuracy 0.802 Validation Loss: 0.336, Validation accuracy 0.892,Epoch runtime: 313.32176899909973\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 76/200, Training Loss: 0.651, Train accuracy 0.805 Validation Loss: 0.353, Validation accuracy 0.895,Epoch runtime: 314.87761092185974\n",
      "Epoch: 77/200, Training Loss: 0.658, Train accuracy 0.802 Validation Loss: 0.385, Validation accuracy 0.873,Epoch runtime: 314.6078748703003\n",
      "Epoch: 78/200, Training Loss: 0.652, Train accuracy 0.804 Validation Loss: 0.465, Validation accuracy 0.857,Epoch runtime: 314.1430537700653\n",
      "Epoch: 79/200, Training Loss: 0.656, Train accuracy 0.804 Validation Loss: 0.409, Validation accuracy 0.872,Epoch runtime: 316.20805621147156\n",
      "Epoch: 80/200, Training Loss: 0.666, Train accuracy 0.799 Validation Loss: 0.402, Validation accuracy 0.878,Epoch runtime: 314.70456647872925\n",
      "Epoch: 81/200, Training Loss: 0.668, Train accuracy 0.799 Validation Loss: 0.524, Validation accuracy 0.844,Epoch runtime: 308.5749411582947\n",
      "Epoch: 82/200, Training Loss: 0.741, Train accuracy 0.784 Validation Loss: 0.418, Validation accuracy 0.870,Epoch runtime: 294.4252784252167\n",
      "Epoch: 83/200, Training Loss: 0.656, Train accuracy 0.804 Validation Loss: 0.456, Validation accuracy 0.862,Epoch runtime: 292.4869680404663\n",
      "Epoch: 84/200, Training Loss: 0.660, Train accuracy 0.803 Validation Loss: 0.372, Validation accuracy 0.886,Epoch runtime: 292.1563596725464\n",
      "Epoch: 85/200, Training Loss: 0.652, Train accuracy 0.805 Validation Loss: 0.392, Validation accuracy 0.880,Epoch runtime: 293.82041788101196\n",
      "Epoch: 86/200, Training Loss: 0.645, Train accuracy 0.807 Validation Loss: 0.362, Validation accuracy 0.883,Epoch runtime: 294.2916498184204\n",
      "Epoch: 87/200, Training Loss: 0.647, Train accuracy 0.804 Validation Loss: 0.407, Validation accuracy 0.876,Epoch runtime: 293.9191429615021\n",
      "Epoch: 88/200, Training Loss: 0.650, Train accuracy 0.803 Validation Loss: 0.381, Validation accuracy 0.887,Epoch runtime: 297.3115768432617\n",
      "Epoch: 89/200, Training Loss: 0.657, Train accuracy 0.803 Validation Loss: 0.424, Validation accuracy 0.867,Epoch runtime: 293.52717566490173\n",
      "Epoch: 90/200, Training Loss: 0.663, Train accuracy 0.801 Validation Loss: 0.356, Validation accuracy 0.892,Epoch runtime: 295.3233850002289\n",
      "Epoch: 91/200, Training Loss: 0.640, Train accuracy 0.807 Validation Loss: 0.401, Validation accuracy 0.879,Epoch runtime: 296.48526668548584\n",
      "Epoch: 92/200, Training Loss: 0.802, Train accuracy 0.766 Validation Loss: 0.506, Validation accuracy 0.844,Epoch runtime: 296.84929299354553\n",
      "Epoch: 93/200, Training Loss: 0.691, Train accuracy 0.794 Validation Loss: 0.422, Validation accuracy 0.870,Epoch runtime: 296.57901549339294\n",
      "Epoch: 94/200, Training Loss: 0.649, Train accuracy 0.805 Validation Loss: 0.480, Validation accuracy 0.859,Epoch runtime: 295.955682516098\n",
      "Epoch: 95/200, Training Loss: 0.644, Train accuracy 0.807 Validation Loss: 0.399, Validation accuracy 0.877,Epoch runtime: 295.5921733379364\n",
      "Stopping early at epoch: 95/200\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=True)\n",
    "\n",
    "mlflow.set_experiment(\"Plant Leaf Disease\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param('framework', 'pytorch')\n",
    "    mlflow.log_param('data_split', '90/10')\n",
    "    mlflow.log_param('type', '9_layer_CNN')\n",
    "    mlflow.log_params(config)\n",
    "    train(model, train_loader, validation_loader, config, n_epochs=config['max_epochs'], stopping_treshold=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
