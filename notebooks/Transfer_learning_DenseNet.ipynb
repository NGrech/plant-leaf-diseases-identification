{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import mlflow\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from collections import OrderedDict\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning with DenseNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "                                      ])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "                                    ])\n",
    "\n",
    "# setting up data loaders\n",
    "data_dir = os.path.join(os.pardir, 'data', 'Plant_leave_diseases_224')\n",
    "\n",
    "train_data = datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(os.path.join(data_dir, 'validation'), transform=test_transforms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Resnet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.densenet121(pretrained=True)\n",
    "\n",
    "# Freezing the paramiters of the layers we do not want to train\n",
    "for parameters in model.parameters():\n",
    "    parameters.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating Classification layer \n",
    "_inputs = model.classifier.in_features\n",
    "\n",
    "model.classifier = nn.Sequential(OrderedDict([\n",
    "    ('fc1', nn.Linear(_inputs, 500)),\n",
    "    ('relu', nn.ReLU()),\n",
    "    ('dropout', nn.Dropout(0.2)),\n",
    "    ('fc2', nn.Linear(500, 39)),\n",
    "    ('output', nn.LogSoftmax(dim=1))\n",
    "]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs \n",
    "config = {\n",
    "    'max_epochs': 200,\n",
    "    'learning_rate': 0.003,\n",
    "    'resolution': 32,\n",
    "    'name': 'densnet'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, validation_loader, config, n_epochs=10, stopping_treshold=None):\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        print('CUDA is available!  Training on GPU ...')\n",
    "        model.cuda()\n",
    "\n",
    "\n",
    "    # Loss and optimizer setup \n",
    "    criterion = nn.NLLLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "\n",
    "    # Setting minimum validation loss to inf\n",
    "    validation_loss_minimum = np.Inf \n",
    "    train_loss_history = []\n",
    "    validation_loss_history = []\n",
    "\n",
    "    for epoch in range(1, n_epochs +1):\n",
    "\n",
    "        training_loss = 0.0\n",
    "        validation_loss = 0.0\n",
    "\n",
    "        # Training loop\n",
    "        training_accuracies = []\n",
    "        for X, y in train_loader:\n",
    "            \n",
    "            # Moving data to gpu if using \n",
    "            if torch.cuda.is_available():\n",
    "                X, y = X.cuda(), y.cuda()\n",
    "            \n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(X)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, y)\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # update training loss\n",
    "            training_loss += loss.item()*X.size(0)\n",
    "\n",
    "            # calculating accuracy\n",
    "            ps = torch.exp(output)\n",
    "            top_p, top_class = ps.topk(1, dim=1)\n",
    "            equals = top_class == y.view(*top_class.shape)\n",
    "            training_accuracies.append(torch.mean(equals.type(torch.FloatTensor)).item())\n",
    "\n",
    "        # Validation Loop\n",
    "        with torch.no_grad():\n",
    "            accuracies = []\n",
    "            for X, y in validation_loader:\n",
    "\n",
    "                # Moving data to gpu if using \n",
    "                if torch.cuda.is_available():\n",
    "                    X, y = X.cuda(), y.cuda()\n",
    "                # forward pass: compute predicted outputs by passing inputs to the model\n",
    "                output = model(X)\n",
    "                # calculate the batch loss\n",
    "                loss = criterion(output, y)\n",
    "                # update validation loss\n",
    "                validation_loss += loss.item()*X.size(0)\n",
    "\n",
    "                # calculating accuracy\n",
    "                ps = torch.exp(output)\n",
    "                top_p, top_class = ps.topk(1, dim=1)\n",
    "                equals = top_class == y.view(*top_class.shape)\n",
    "                accuracies.append(torch.mean(equals.type(torch.FloatTensor)).item())\n",
    "                \n",
    "        # Mean loss \n",
    "        mean_training_loss = training_loss/len(train_loader.sampler)\n",
    "        mean_validation_loss = validation_loss/len(validation_loader.sampler)\n",
    "        mean_train_accuracy = sum(training_accuracies)/len(training_accuracies)\n",
    "        mean_accuracy = sum(accuracies)/len(accuracies)\n",
    "        train_loss_history.append(mean_training_loss)\n",
    "        validation_loss_history.append(mean_validation_loss)\n",
    "\n",
    "        # Printing epoch stats\n",
    "        print(f'Epoch: {epoch}/{n_epochs}, ' +\\\n",
    "              f'Training Loss: {mean_training_loss:.3f}, '+\\\n",
    "              f'Train accuracy {mean_train_accuracy:.3f} ' +\\\n",
    "              f'Validation Loss: {mean_validation_loss:.3f}, '+\\\n",
    "              f'Validation accuracy {mean_accuracy:.3f}')\n",
    "\n",
    "        # logging with mlflow \n",
    "        if mlflow.active_run():\n",
    "            mlflow.log_metric('loss', mean_training_loss, step=epoch)\n",
    "            mlflow.log_metric('accuracy', mean_train_accuracy, step=epoch)\n",
    "            mlflow.log_metric('validation_accuracy', mean_accuracy, step=epoch)\n",
    "            mlflow.log_metric('validation_loss', mean_validation_loss, step=epoch)\n",
    "\n",
    "        # Testing for early stopping\n",
    "        if stopping_treshold:\n",
    "            if mean_validation_loss < validation_loss_minimum:\n",
    "                validation_loss_minimum = mean_validation_loss\n",
    "                print('New minimum validation loss (saving model)')\n",
    "                save_pth = os.path.join('models',f'{config[\"name\"]}.pt')\n",
    "                torch.save(model.state_dict(), save_pth)\n",
    "            elif len([v for v in validation_loss_history[-stopping_treshold:] if v > validation_loss_minimum]) >= stopping_treshold:\n",
    "                print(f\"Stopping early at epoch: {epoch}/{n_epochs}\")\n",
    "                break\n",
    "        \n",
    "\n",
    "    return train_loss_history, validation_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n",
      "Epoch: 1/200, Training Loss: 0.920, Train accuracy 0.728 Validation Loss: 0.351, Validation accuracy 0.882\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 2/200, Training Loss: 0.635, Train accuracy 0.804 Validation Loss: 0.320, Validation accuracy 0.893\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 3/200, Training Loss: 0.612, Train accuracy 0.812 Validation Loss: 0.339, Validation accuracy 0.890\n",
      "Epoch: 4/200, Training Loss: 0.588, Train accuracy 0.821 Validation Loss: 0.294, Validation accuracy 0.904\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 5/200, Training Loss: 0.570, Train accuracy 0.826 Validation Loss: 0.284, Validation accuracy 0.908\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 6/200, Training Loss: 0.565, Train accuracy 0.826 Validation Loss: 0.266, Validation accuracy 0.916\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 7/200, Training Loss: 0.546, Train accuracy 0.831 Validation Loss: 0.263, Validation accuracy 0.911\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 8/200, Training Loss: 0.550, Train accuracy 0.834 Validation Loss: 0.249, Validation accuracy 0.913\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 9/200, Training Loss: 0.536, Train accuracy 0.837 Validation Loss: 0.264, Validation accuracy 0.911\n",
      "Epoch: 10/200, Training Loss: 0.527, Train accuracy 0.840 Validation Loss: 0.271, Validation accuracy 0.911\n",
      "Epoch: 11/200, Training Loss: 0.531, Train accuracy 0.839 Validation Loss: 0.258, Validation accuracy 0.915\n",
      "Epoch: 12/200, Training Loss: 0.518, Train accuracy 0.842 Validation Loss: 0.226, Validation accuracy 0.929\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 13/200, Training Loss: 0.528, Train accuracy 0.841 Validation Loss: 0.251, Validation accuracy 0.917\n",
      "Epoch: 14/200, Training Loss: 0.515, Train accuracy 0.844 Validation Loss: 0.256, Validation accuracy 0.917\n",
      "Epoch: 15/200, Training Loss: 0.497, Train accuracy 0.849 Validation Loss: 0.241, Validation accuracy 0.925\n",
      "Epoch: 16/200, Training Loss: 0.512, Train accuracy 0.847 Validation Loss: 0.219, Validation accuracy 0.933\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 17/200, Training Loss: 0.513, Train accuracy 0.847 Validation Loss: 0.235, Validation accuracy 0.925\n",
      "Epoch: 18/200, Training Loss: 0.497, Train accuracy 0.848 Validation Loss: 0.217, Validation accuracy 0.931\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 19/200, Training Loss: 0.494, Train accuracy 0.852 Validation Loss: 0.252, Validation accuracy 0.920\n",
      "Epoch: 20/200, Training Loss: 0.495, Train accuracy 0.852 Validation Loss: 0.214, Validation accuracy 0.931\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 21/200, Training Loss: 0.485, Train accuracy 0.854 Validation Loss: 0.234, Validation accuracy 0.923\n",
      "Epoch: 22/200, Training Loss: 0.487, Train accuracy 0.855 Validation Loss: 0.235, Validation accuracy 0.923\n",
      "Epoch: 23/200, Training Loss: 0.491, Train accuracy 0.853 Validation Loss: 0.208, Validation accuracy 0.936\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 24/200, Training Loss: 0.489, Train accuracy 0.854 Validation Loss: 0.222, Validation accuracy 0.929\n",
      "Epoch: 25/200, Training Loss: 0.474, Train accuracy 0.858 Validation Loss: 0.243, Validation accuracy 0.921\n",
      "Epoch: 26/200, Training Loss: 0.478, Train accuracy 0.855 Validation Loss: 0.215, Validation accuracy 0.932\n",
      "Epoch: 27/200, Training Loss: 0.475, Train accuracy 0.856 Validation Loss: 0.223, Validation accuracy 0.933\n",
      "Epoch: 28/200, Training Loss: 0.478, Train accuracy 0.857 Validation Loss: 0.242, Validation accuracy 0.925\n",
      "Epoch: 29/200, Training Loss: 0.474, Train accuracy 0.858 Validation Loss: 0.196, Validation accuracy 0.939\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 30/200, Training Loss: 0.478, Train accuracy 0.857 Validation Loss: 0.215, Validation accuracy 0.930\n",
      "Epoch: 31/200, Training Loss: 0.472, Train accuracy 0.859 Validation Loss: 0.207, Validation accuracy 0.934\n",
      "Epoch: 32/200, Training Loss: 0.472, Train accuracy 0.860 Validation Loss: 0.216, Validation accuracy 0.935\n",
      "Epoch: 33/200, Training Loss: 0.470, Train accuracy 0.860 Validation Loss: 0.210, Validation accuracy 0.936\n",
      "Epoch: 34/200, Training Loss: 0.466, Train accuracy 0.861 Validation Loss: 0.202, Validation accuracy 0.938\n",
      "Epoch: 35/200, Training Loss: 0.456, Train accuracy 0.862 Validation Loss: 0.226, Validation accuracy 0.930\n",
      "Epoch: 36/200, Training Loss: 0.464, Train accuracy 0.863 Validation Loss: 0.222, Validation accuracy 0.929\n",
      "Epoch: 37/200, Training Loss: 0.468, Train accuracy 0.861 Validation Loss: 0.197, Validation accuracy 0.936\n",
      "Epoch: 38/200, Training Loss: 0.466, Train accuracy 0.861 Validation Loss: 0.200, Validation accuracy 0.935\n",
      "Epoch: 39/200, Training Loss: 0.467, Train accuracy 0.864 Validation Loss: 0.245, Validation accuracy 0.921\n",
      "Epoch: 40/200, Training Loss: 0.463, Train accuracy 0.865 Validation Loss: 0.201, Validation accuracy 0.938\n",
      "Epoch: 41/200, Training Loss: 0.454, Train accuracy 0.866 Validation Loss: 0.225, Validation accuracy 0.936\n",
      "Epoch: 42/200, Training Loss: 0.460, Train accuracy 0.865 Validation Loss: 0.228, Validation accuracy 0.931\n",
      "Epoch: 43/200, Training Loss: 0.455, Train accuracy 0.865 Validation Loss: 0.238, Validation accuracy 0.926\n",
      "Epoch: 44/200, Training Loss: 0.451, Train accuracy 0.866 Validation Loss: 0.198, Validation accuracy 0.939\n",
      "Stopping early at epoch: 44/200\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=True)\n",
    "\n",
    "mlflow.set_experiment(\"Plant Leaf Disease\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param('framework', 'pytorch')\n",
    "    mlflow.log_param('data_split', '90/10')\n",
    "    mlflow.log_param('type', 'DenseNet121')\n",
    "    mlflow.log_params(config)\n",
    "    train(model, train_loader, validation_loader, config, n_epochs=config['max_epochs'], stopping_treshold=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d53c06ab4573055b295bcdfb3b25bc2da21e5ae576a05184a9c53fc2168185ab"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('plant-leaf-diseases-identification-CBiGMIHu-py3.8': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
