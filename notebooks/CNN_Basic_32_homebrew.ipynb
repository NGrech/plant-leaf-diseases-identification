{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29ee38e8",
   "metadata": {},
   "source": [
    "# Implementation of Basic Homebrew CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5b2250c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'model' from '..\\\\src\\\\model.py'>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# General imports \n",
    "import sys\n",
    "import os \n",
    "sys.path.insert(1, os.path.join(os.pardir, 'src'))\n",
    "from itertools import product\n",
    "\n",
    "# Data imports\n",
    "import torch\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Homebrew imports \n",
    "import model\n",
    "from utils import one_hot_encode_index\n",
    "from optimizers import Adam\n",
    "from activations import Softmax, ReLU\n",
    "from layers import Dropout, LinearLayer, ConvolutionLayer, PoolingLayer, FlattenLayer\n",
    "from loss import CategoricalCrossEntropyLoss\n",
    "\n",
    "## TESTING \n",
    "import importlib\n",
    "importlib.reload(model)\n",
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dbb6cc",
   "metadata": {},
   "source": [
    "## Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d69b9a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(32),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "                                      ])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(33),\n",
    "                                      transforms.CenterCrop(32),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "                                    ])\n",
    "\n",
    "# setting up data loaders\n",
    "data_dir = os.path.join(os.pardir, 'data', 'Plant_leave_diseases_32')\n",
    "\n",
    "train_data = datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(os.path.join(data_dir, 'validation'), transform=test_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51af43ca",
   "metadata": {},
   "source": [
    "### Train config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7d59977a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs \n",
    "config = {\n",
    "    'max_epochs': 100,\n",
    "    'learning_rate': 0.003,\n",
    "    'resolution': 32,\n",
    "    'name': 'CNN_LeNet_inspired_homebrew'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ce71e6",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a3b2d3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Architecture: \n",
      "+------------------+-----------+------------+\n",
      "|      Layer       | Trainable | Parameters |\n",
      "+------------------+-----------+------------+\n",
      "| ConvolutionLayer |    True   |    1350    |\n",
      "|       ReLU       |   False   |     0      |\n",
      "|   PoolingLayer   |   False   |     0      |\n",
      "| ConvolutionLayer |    True   |   12600    |\n",
      "|       ReLU       |   False   |     0      |\n",
      "|   PoolingLayer   |   False   |     0      |\n",
      "|   FlattenLayer   |   False   |     0      |\n",
      "|   LinearLayer    |    True   |   84120    |\n",
      "|       ReLU       |   False   |     0      |\n",
      "|   LinearLayer    |    True   |    4719    |\n",
      "|     Softmax      |   False   |     0      |\n",
      "+------------------+-----------+------------+\n",
      "Total: 102,789\n"
     ]
    }
   ],
   "source": [
    "mdl = model.Model(Adam(learning_rate=config['learning_rate']),\n",
    "                      CategoricalCrossEntropyLoss())\n",
    "\n",
    "# Config early stop \n",
    "mdl.add_early_stop(5)\n",
    "\n",
    "mdl.set_save_config(model_name=config['name'], save_path=os.path.join('models'))\n",
    "\n",
    "# Defining architecture \n",
    "\n",
    "mdl.set_sequence([\n",
    "                    ConvolutionLayer(3, 18, 5),\n",
    "                    ReLU(),\n",
    "                    PoolingLayer(18, 2),\n",
    "                    ConvolutionLayer(18, 28, 5),\n",
    "                    ReLU(),\n",
    "                    PoolingLayer(28, 2),\n",
    "                    FlattenLayer(),\n",
    "                    LinearLayer(700, 120),\n",
    "                    ReLU(),\n",
    "                    LinearLayer(120, 39),\n",
    "                    Softmax()\n",
    "                ])\n",
    "print(mdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "14df8745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch: 1 ===\n",
      "Step: 0/217, accuracy0.023, loss3.893, learning rate 0.0030000 \n",
      "Step: 5/217, accuracy0.121, loss9.914, learning rate 0.0030000 \n",
      "Step: 10/217, accuracy0.074, loss3.628, learning rate 0.0030000 \n",
      "Step: 15/217, accuracy0.051, loss3.643, learning rate 0.0030000 \n",
      "Step: 20/217, accuracy0.094, loss3.591, learning rate 0.0030000 \n",
      "Step: 25/217, accuracy0.078, loss3.601, learning rate 0.0030000 \n",
      "Step: 30/217, accuracy0.090, loss3.651, learning rate 0.0030000 \n",
      "Step: 35/217, accuracy0.094, loss3.515, learning rate 0.0030000 \n",
      "Step: 40/217, accuracy0.105, loss3.495, learning rate 0.0030000 \n",
      "Step: 45/217, accuracy0.043, loss3.564, learning rate 0.0030000 \n",
      "Step: 50/217, accuracy0.082, loss3.493, learning rate 0.0030000 \n",
      "Step: 55/217, accuracy0.105, loss3.507, learning rate 0.0030000 \n",
      "Step: 60/217, accuracy0.098, loss3.504, learning rate 0.0030000 \n",
      "Step: 65/217, accuracy0.070, loss3.486, learning rate 0.0030000 \n",
      "Step: 70/217, accuracy0.109, loss3.483, learning rate 0.0030000 \n",
      "Step: 75/217, accuracy0.121, loss3.455, learning rate 0.0030000 \n",
      "Step: 80/217, accuracy0.172, loss3.426, learning rate 0.0030000 \n",
      "Step: 85/217, accuracy0.125, loss3.447, learning rate 0.0030000 \n",
      "Step: 90/217, accuracy0.125, loss3.525, learning rate 0.0030000 \n",
      "Step: 95/217, accuracy0.125, loss3.426, learning rate 0.0030000 \n",
      "Step: 100/217, accuracy0.121, loss3.332, learning rate 0.0030000 \n",
      "Step: 105/217, accuracy0.133, loss3.480, learning rate 0.0030000 \n",
      "Step: 110/217, accuracy0.133, loss3.434, learning rate 0.0030000 \n",
      "Step: 115/217, accuracy0.078, loss3.449, learning rate 0.0030000 \n",
      "Step: 120/217, accuracy0.141, loss3.408, learning rate 0.0030000 \n",
      "Step: 125/217, accuracy0.133, loss3.398, learning rate 0.0030000 \n",
      "Step: 130/217, accuracy0.137, loss3.359, learning rate 0.0030000 \n",
      "Step: 135/217, accuracy0.145, loss3.388, learning rate 0.0030000 \n",
      "Step: 140/217, accuracy0.113, loss3.387, learning rate 0.0030000 \n",
      "Step: 145/217, accuracy0.090, loss3.455, learning rate 0.0030000 \n",
      "Step: 150/217, accuracy0.090, loss3.485, learning rate 0.0030000 \n",
      "Step: 155/217, accuracy0.145, loss3.365, learning rate 0.0030000 \n",
      "Step: 160/217, accuracy0.094, loss3.406, learning rate 0.0030000 \n",
      "Step: 165/217, accuracy0.121, loss3.386, learning rate 0.0030000 \n",
      "Step: 170/217, accuracy0.141, loss3.252, learning rate 0.0030000 \n",
      "Step: 175/217, accuracy0.141, loss3.336, learning rate 0.0030000 \n",
      "Step: 180/217, accuracy0.105, loss3.391, learning rate 0.0030000 \n",
      "Step: 185/217, accuracy0.152, loss3.344, learning rate 0.0030000 \n",
      "Step: 190/217, accuracy0.125, loss3.329, learning rate 0.0030000 \n",
      "Step: 195/217, accuracy0.109, loss3.429, learning rate 0.0030000 \n",
      "Step: 200/217, accuracy0.125, loss3.357, learning rate 0.0030000 \n",
      "Step: 205/217, accuracy0.133, loss3.287, learning rate 0.0030000 \n",
      "Step: 210/217, accuracy0.141, loss3.332, learning rate 0.0030000 \n",
      "Step: 215/217, accuracy0.117, loss3.439, learning rate 0.0030000 \n",
      "Step: 216/217, accuracy0.032, loss3.480, learning rate 0.0030000 \n",
      "Epoch: 1/100, accuracy0.108, loss3.598, learning rate 0.003\n",
      "Estimated reamining runtime: 6 days, 14:56:33.315840\n",
      "--Validation--\n",
      "Validation : Accuracy: 0.158, Loss: 3.277\n",
      "=== Epoch: 2 ===\n",
      "Step: 0/217, accuracy0.145, loss3.364, learning rate 0.0030000 \n",
      "Step: 5/217, accuracy0.113, loss3.323, learning rate 0.0030000 \n",
      "Step: 10/217, accuracy0.152, loss3.319, learning rate 0.0030000 \n",
      "Step: 15/217, accuracy0.094, loss3.400, learning rate 0.0030000 \n",
      "Step: 20/217, accuracy0.180, loss3.233, learning rate 0.0030000 \n",
      "Step: 25/217, accuracy0.129, loss3.305, learning rate 0.0030000 \n",
      "Step: 30/217, accuracy0.152, loss3.294, learning rate 0.0030000 \n",
      "Step: 35/217, accuracy0.172, loss3.256, learning rate 0.0030000 \n",
      "Step: 40/217, accuracy0.129, loss3.360, learning rate 0.0030000 \n",
      "Step: 45/217, accuracy0.105, loss3.319, learning rate 0.0030000 \n",
      "Step: 50/217, accuracy0.137, loss3.220, learning rate 0.0030000 \n",
      "Step: 55/217, accuracy0.129, loss3.330, learning rate 0.0030000 \n",
      "Step: 60/217, accuracy0.129, loss3.314, learning rate 0.0030000 \n",
      "Step: 65/217, accuracy0.113, loss3.445, learning rate 0.0030000 \n",
      "Step: 70/217, accuracy0.164, loss3.201, learning rate 0.0030000 \n",
      "Step: 75/217, accuracy0.137, loss3.304, learning rate 0.0030000 \n",
      "Step: 80/217, accuracy0.133, loss3.357, learning rate 0.0030000 \n",
      "Step: 85/217, accuracy0.082, loss3.404, learning rate 0.0030000 \n",
      "Step: 90/217, accuracy0.121, loss3.261, learning rate 0.0030000 \n",
      "Step: 95/217, accuracy0.129, loss3.384, learning rate 0.0030000 \n",
      "Step: 100/217, accuracy0.117, loss3.374, learning rate 0.0030000 \n",
      "Step: 105/217, accuracy0.121, loss3.395, learning rate 0.0030000 \n",
      "Step: 110/217, accuracy0.105, loss3.342, learning rate 0.0030000 \n",
      "Step: 115/217, accuracy0.145, loss3.325, learning rate 0.0030000 \n",
      "Step: 120/217, accuracy0.121, loss3.355, learning rate 0.0030000 \n",
      "Step: 125/217, accuracy0.113, loss3.350, learning rate 0.0030000 \n",
      "Step: 130/217, accuracy0.156, loss3.388, learning rate 0.0030000 \n",
      "Step: 135/217, accuracy0.121, loss3.267, learning rate 0.0030000 \n",
      "Step: 140/217, accuracy0.133, loss3.303, learning rate 0.0030000 \n",
      "Step: 145/217, accuracy0.121, loss3.364, learning rate 0.0030000 \n",
      "Step: 150/217, accuracy0.113, loss3.393, learning rate 0.0030000 \n",
      "Step: 155/217, accuracy0.105, loss3.311, learning rate 0.0030000 \n",
      "Step: 160/217, accuracy0.098, loss3.386, learning rate 0.0030000 \n",
      "Step: 165/217, accuracy0.141, loss3.314, learning rate 0.0030000 \n",
      "Step: 170/217, accuracy0.074, loss3.472, learning rate 0.0030000 \n",
      "Step: 175/217, accuracy0.137, loss3.265, learning rate 0.0030000 \n",
      "Step: 180/217, accuracy0.121, loss3.303, learning rate 0.0030000 \n",
      "Step: 185/217, accuracy0.113, loss3.370, learning rate 0.0030000 \n",
      "Step: 190/217, accuracy0.152, loss3.323, learning rate 0.0030000 \n",
      "Step: 195/217, accuracy0.090, loss3.428, learning rate 0.0030000 \n",
      "Step: 200/217, accuracy0.113, loss3.426, learning rate 0.0030000 \n",
      "Step: 205/217, accuracy0.117, loss3.396, learning rate 0.0030000 \n",
      "Step: 210/217, accuracy0.102, loss3.418, learning rate 0.0030000 \n",
      "Step: 215/217, accuracy0.090, loss3.386, learning rate 0.0030000 \n",
      "Step: 216/217, accuracy0.097, loss3.248, learning rate 0.0030000 \n",
      "Epoch: 2/100, accuracy0.120, loss3.355, learning rate 0.003\n",
      "Estimated reamining runtime: 6 days, 15:35:26.237440\n",
      "--Validation--\n",
      "Validation : Accuracy: 0.136, Loss: 3.291\n",
      "=== Epoch: 3 ===\n",
      "Step: 0/217, accuracy0.098, loss3.388, learning rate 0.0030000 \n",
      "Step: 5/217, accuracy0.141, loss3.311, learning rate 0.0030000 \n",
      "Step: 10/217, accuracy0.129, loss3.284, learning rate 0.0030000 \n",
      "Step: 15/217, accuracy0.164, loss3.294, learning rate 0.0030000 \n",
      "Step: 20/217, accuracy0.117, loss3.342, learning rate 0.0030000 \n",
      "Step: 25/217, accuracy0.121, loss3.361, learning rate 0.0030000 \n",
      "Step: 30/217, accuracy0.129, loss3.358, learning rate 0.0030000 \n",
      "Step: 35/217, accuracy0.156, loss3.282, learning rate 0.0030000 \n",
      "Step: 40/217, accuracy0.102, loss3.305, learning rate 0.0030000 \n",
      "Step: 45/217, accuracy0.102, loss3.320, learning rate 0.0030000 \n",
      "Step: 50/217, accuracy0.109, loss3.379, learning rate 0.0030000 \n",
      "Step: 55/217, accuracy0.090, loss3.457, learning rate 0.0030000 \n",
      "Step: 60/217, accuracy0.086, loss3.422, learning rate 0.0030000 \n",
      "Step: 65/217, accuracy0.070, loss3.391, learning rate 0.0030000 \n",
      "Step: 70/217, accuracy0.109, loss3.380, learning rate 0.0030000 \n",
      "Step: 75/217, accuracy0.098, loss3.407, learning rate 0.0030000 \n",
      "Step: 80/217, accuracy0.129, loss3.302, learning rate 0.0030000 \n",
      "Step: 85/217, accuracy0.129, loss3.370, learning rate 0.0030000 \n",
      "Step: 90/217, accuracy0.105, loss3.308, learning rate 0.0030000 \n",
      "Step: 95/217, accuracy0.156, loss3.279, learning rate 0.0030000 \n",
      "Step: 100/217, accuracy0.105, loss3.411, learning rate 0.0030000 \n",
      "Step: 105/217, accuracy0.070, loss3.420, learning rate 0.0030000 \n",
      "Step: 110/217, accuracy0.129, loss3.389, learning rate 0.0030000 \n",
      "Step: 115/217, accuracy0.102, loss3.429, learning rate 0.0030000 \n",
      "Step: 120/217, accuracy0.152, loss3.296, learning rate 0.0030000 \n",
      "Step: 125/217, accuracy0.113, loss3.413, learning rate 0.0030000 \n",
      "Step: 130/217, accuracy0.117, loss3.336, learning rate 0.0030000 \n",
      "Step: 135/217, accuracy0.094, loss3.356, learning rate 0.0030000 \n",
      "Step: 140/217, accuracy0.074, loss3.521, learning rate 0.0030000 \n",
      "Step: 145/217, accuracy0.145, loss3.357, learning rate 0.0030000 \n",
      "Step: 150/217, accuracy0.125, loss3.364, learning rate 0.0030000 \n",
      "Step: 155/217, accuracy0.129, loss3.417, learning rate 0.0030000 \n",
      "Step: 160/217, accuracy0.113, loss3.316, learning rate 0.0030000 \n",
      "Step: 165/217, accuracy0.137, loss3.319, learning rate 0.0030000 \n",
      "Step: 170/217, accuracy0.094, loss3.419, learning rate 0.0030000 \n",
      "Step: 175/217, accuracy0.105, loss3.319, learning rate 0.0030000 \n",
      "Step: 180/217, accuracy0.152, loss3.326, learning rate 0.0030000 \n",
      "Step: 185/217, accuracy0.098, loss3.397, learning rate 0.0030000 \n",
      "Step: 190/217, accuracy0.117, loss3.327, learning rate 0.0030000 \n",
      "Step: 195/217, accuracy0.113, loss3.326, learning rate 0.0030000 \n",
      "Step: 200/217, accuracy0.117, loss3.441, learning rate 0.0030000 \n",
      "Step: 205/217, accuracy0.109, loss3.385, learning rate 0.0030000 \n",
      "Step: 210/217, accuracy0.086, loss3.417, learning rate 0.0030000 \n",
      "Step: 215/217, accuracy0.105, loss3.354, learning rate 0.0030000 \n",
      "Step: 216/217, accuracy0.097, loss3.289, learning rate 0.0030000 \n",
      "Epoch: 3/100, accuracy0.118, loss3.385, learning rate 0.003\n",
      "Estimated reamining runtime: 6 days, 15:33:27.995979\n",
      "--Validation--\n",
      "Validation : Accuracy: 0.134, Loss: 3.292\n",
      "=== Epoch: 4 ===\n",
      "Step: 0/217, accuracy0.102, loss3.420, learning rate 0.0030000 \n",
      "Step: 5/217, accuracy0.102, loss3.439, learning rate 0.0030000 \n",
      "Step: 10/217, accuracy0.098, loss3.474, learning rate 0.0030000 \n",
      "Step: 15/217, accuracy0.125, loss3.332, learning rate 0.0030000 \n",
      "Step: 20/217, accuracy0.121, loss3.348, learning rate 0.0030000 \n",
      "Step: 25/217, accuracy0.137, loss3.342, learning rate 0.0030000 \n",
      "Step: 30/217, accuracy0.125, loss3.324, learning rate 0.0030000 \n",
      "Step: 35/217, accuracy0.090, loss3.381, learning rate 0.0030000 \n",
      "Step: 40/217, accuracy0.109, loss3.321, learning rate 0.0030000 \n",
      "Step: 45/217, accuracy0.082, loss3.425, learning rate 0.0030000 \n",
      "Step: 50/217, accuracy0.117, loss3.361, learning rate 0.0030000 \n",
      "Step: 55/217, accuracy0.137, loss3.368, learning rate 0.0030000 \n",
      "Step: 60/217, accuracy0.148, loss3.263, learning rate 0.0030000 \n",
      "Step: 65/217, accuracy0.102, loss3.347, learning rate 0.0030000 \n",
      "Step: 70/217, accuracy0.160, loss3.261, learning rate 0.0030000 \n",
      "Step: 75/217, accuracy0.141, loss3.342, learning rate 0.0030000 \n",
      "Step: 80/217, accuracy0.094, loss3.303, learning rate 0.0030000 \n",
      "Step: 85/217, accuracy0.145, loss3.314, learning rate 0.0030000 \n",
      "Step: 90/217, accuracy0.105, loss3.408, learning rate 0.0030000 \n",
      "Step: 95/217, accuracy0.121, loss3.315, learning rate 0.0030000 \n",
      "Step: 100/217, accuracy0.090, loss3.411, learning rate 0.0030000 \n",
      "Step: 105/217, accuracy0.102, loss3.300, learning rate 0.0030000 \n",
      "Step: 110/217, accuracy0.117, loss3.397, learning rate 0.0030000 \n",
      "Step: 115/217, accuracy0.117, loss3.315, learning rate 0.0030000 \n",
      "Step: 120/217, accuracy0.121, loss3.366, learning rate 0.0030000 \n",
      "Step: 125/217, accuracy0.098, loss3.302, learning rate 0.0030000 \n",
      "Step: 130/217, accuracy0.117, loss3.392, learning rate 0.0030000 \n",
      "Step: 135/217, accuracy0.090, loss3.369, learning rate 0.0030000 \n",
      "Step: 140/217, accuracy0.113, loss3.315, learning rate 0.0030000 \n",
      "Step: 145/217, accuracy0.125, loss3.349, learning rate 0.0030000 \n",
      "Step: 150/217, accuracy0.152, loss3.374, learning rate 0.0030000 \n",
      "Step: 155/217, accuracy0.133, loss3.379, learning rate 0.0030000 \n",
      "Step: 160/217, accuracy0.105, loss3.364, learning rate 0.0030000 \n",
      "Step: 165/217, accuracy0.105, loss3.368, learning rate 0.0030000 \n",
      "Step: 170/217, accuracy0.113, loss3.350, learning rate 0.0030000 \n",
      "Step: 175/217, accuracy0.121, loss3.343, learning rate 0.0030000 \n",
      "Step: 180/217, accuracy0.105, loss3.419, learning rate 0.0030000 \n",
      "Step: 185/217, accuracy0.133, loss3.266, learning rate 0.0030000 \n",
      "Step: 190/217, accuracy0.129, loss3.327, learning rate 0.0030000 \n",
      "Step: 195/217, accuracy0.129, loss3.313, learning rate 0.0030000 \n",
      "Step: 200/217, accuracy0.133, loss3.320, learning rate 0.0030000 \n",
      "Step: 205/217, accuracy0.113, loss3.336, learning rate 0.0030000 \n",
      "Step: 210/217, accuracy0.090, loss3.404, learning rate 0.0030000 \n",
      "Step: 215/217, accuracy0.082, loss3.338, learning rate 0.0030000 \n",
      "Step: 216/217, accuracy0.065, loss3.278, learning rate 0.0030000 \n",
      "Epoch: 4/100, accuracy0.119, loss3.395, learning rate 0.003\n",
      "Estimated reamining runtime: 6 days, 15:20:15.769744\n",
      "--Validation--\n",
      "Validation : Accuracy: 0.130, Loss: 3.303\n",
      "=== Epoch: 5 ===\n",
      "Step: 0/217, accuracy0.105, loss3.336, learning rate 0.0030000 \n",
      "Step: 5/217, accuracy0.105, loss3.340, learning rate 0.0030000 \n",
      "Step: 10/217, accuracy0.129, loss3.294, learning rate 0.0030000 \n",
      "Step: 15/217, accuracy0.098, loss3.406, learning rate 0.0030000 \n",
      "Step: 20/217, accuracy0.141, loss3.324, learning rate 0.0030000 \n",
      "Step: 25/217, accuracy0.145, loss3.232, learning rate 0.0030000 \n",
      "Step: 30/217, accuracy0.125, loss3.321, learning rate 0.0030000 \n",
      "Step: 35/217, accuracy0.109, loss3.382, learning rate 0.0030000 \n",
      "Step: 40/217, accuracy0.102, loss3.343, learning rate 0.0030000 \n",
      "Step: 45/217, accuracy0.090, loss3.357, learning rate 0.0030000 \n",
      "Step: 50/217, accuracy0.137, loss3.286, learning rate 0.0030000 \n",
      "Step: 55/217, accuracy0.113, loss3.370, learning rate 0.0030000 \n",
      "Step: 60/217, accuracy0.121, loss3.378, learning rate 0.0030000 \n",
      "Step: 65/217, accuracy0.090, loss3.430, learning rate 0.0030000 \n",
      "Step: 70/217, accuracy0.121, loss3.316, learning rate 0.0030000 \n",
      "Step: 75/217, accuracy0.121, loss3.419, learning rate 0.0030000 \n",
      "Step: 80/217, accuracy0.117, loss3.329, learning rate 0.0030000 \n",
      "Step: 85/217, accuracy0.113, loss3.403, learning rate 0.0030000 \n",
      "Step: 90/217, accuracy0.113, loss3.331, learning rate 0.0030000 \n",
      "Step: 95/217, accuracy0.117, loss3.340, learning rate 0.0030000 \n",
      "Step: 100/217, accuracy0.098, loss3.368, learning rate 0.0030000 \n",
      "Step: 105/217, accuracy0.117, loss3.329, learning rate 0.0030000 \n",
      "Step: 110/217, accuracy0.117, loss3.308, learning rate 0.0030000 \n",
      "Step: 115/217, accuracy0.094, loss3.388, learning rate 0.0030000 \n",
      "Step: 120/217, accuracy0.117, loss3.377, learning rate 0.0030000 \n",
      "Step: 125/217, accuracy0.117, loss3.380, learning rate 0.0030000 \n",
      "Step: 130/217, accuracy0.152, loss3.351, learning rate 0.0030000 \n",
      "Step: 135/217, accuracy0.160, loss3.250, learning rate 0.0030000 \n",
      "Step: 140/217, accuracy0.125, loss3.339, learning rate 0.0030000 \n",
      "Step: 145/217, accuracy0.086, loss3.358, learning rate 0.0030000 \n",
      "Step: 150/217, accuracy0.121, loss3.190, learning rate 0.0030000 \n",
      "Step: 155/217, accuracy0.125, loss3.347, learning rate 0.0030000 \n",
      "Step: 160/217, accuracy0.152, loss3.392, learning rate 0.0030000 \n",
      "Step: 165/217, accuracy0.117, loss3.447, learning rate 0.0030000 \n",
      "Step: 170/217, accuracy0.098, loss3.407, learning rate 0.0030000 \n",
      "Step: 175/217, accuracy0.117, loss3.322, learning rate 0.0030000 \n",
      "Step: 180/217, accuracy0.094, loss3.313, learning rate 0.0030000 \n",
      "Step: 185/217, accuracy0.133, loss3.337, learning rate 0.0030000 \n",
      "Step: 190/217, accuracy0.109, loss3.388, learning rate 0.0030000 \n",
      "Step: 195/217, accuracy0.137, loss3.297, learning rate 0.0030000 \n",
      "Step: 200/217, accuracy0.156, loss3.272, learning rate 0.0030000 \n",
      "Step: 205/217, accuracy0.129, loss3.337, learning rate 0.0030000 \n",
      "Step: 210/217, accuracy0.102, loss3.352, learning rate 0.0030000 \n",
      "Step: 215/217, accuracy0.105, loss3.251, learning rate 0.0030000 \n",
      "Step: 216/217, accuracy0.129, loss3.474, learning rate 0.0030000 \n",
      "Epoch: 5/100, accuracy0.119, loss3.354, learning rate 0.003\n",
      "Estimated reamining runtime: 6 days, 13:56:04.544821\n",
      "--Validation--\n",
      "Validation : Accuracy: 0.133, Loss: 3.320\n",
      "=== Epoch: 6 ===\n",
      "Step: 0/217, accuracy0.125, loss3.327, learning rate 0.0030000 \n",
      "Step: 5/217, accuracy0.145, loss3.284, learning rate 0.0030000 \n",
      "Step: 10/217, accuracy0.152, loss3.249, learning rate 0.0030000 \n",
      "Step: 15/217, accuracy0.113, loss3.347, learning rate 0.0030000 \n",
      "Step: 20/217, accuracy0.184, loss3.220, learning rate 0.0030000 \n",
      "Step: 25/217, accuracy0.141, loss3.258, learning rate 0.0030000 \n",
      "Step: 30/217, accuracy0.109, loss3.426, learning rate 0.0030000 \n",
      "Step: 35/217, accuracy0.125, loss3.325, learning rate 0.0030000 \n",
      "Step: 40/217, accuracy0.145, loss3.377, learning rate 0.0030000 \n",
      "Step: 45/217, accuracy0.160, loss3.285, learning rate 0.0030000 \n",
      "Step: 50/217, accuracy0.125, loss3.382, learning rate 0.0030000 \n",
      "Step: 55/217, accuracy0.102, loss3.444, learning rate 0.0030000 \n",
      "Step: 60/217, accuracy0.113, loss3.368, learning rate 0.0030000 \n",
      "Step: 65/217, accuracy0.062, loss3.448, learning rate 0.0030000 \n",
      "Step: 70/217, accuracy0.137, loss3.377, learning rate 0.0030000 \n",
      "Step: 75/217, accuracy0.129, loss3.359, learning rate 0.0030000 \n",
      "Step: 80/217, accuracy0.102, loss3.307, learning rate 0.0030000 \n",
      "Step: 85/217, accuracy0.145, loss3.334, learning rate 0.0030000 \n",
      "Step: 90/217, accuracy0.129, loss3.311, learning rate 0.0030000 \n",
      "Step: 95/217, accuracy0.160, loss3.231, learning rate 0.0030000 \n",
      "Step: 100/217, accuracy0.090, loss3.380, learning rate 0.0030000 \n",
      "Step: 105/217, accuracy0.148, loss3.294, learning rate 0.0030000 \n",
      "Step: 110/217, accuracy0.156, loss3.285, learning rate 0.0030000 \n",
      "Step: 115/217, accuracy0.125, loss3.301, learning rate 0.0030000 \n",
      "Step: 120/217, accuracy0.117, loss3.340, learning rate 0.0030000 \n",
      "Step: 125/217, accuracy0.121, loss3.308, learning rate 0.0030000 \n",
      "Step: 130/217, accuracy0.098, loss3.393, learning rate 0.0030000 \n",
      "Step: 135/217, accuracy0.113, loss3.401, learning rate 0.0030000 \n",
      "Step: 140/217, accuracy0.129, loss3.320, learning rate 0.0030000 \n",
      "Step: 145/217, accuracy0.152, loss3.315, learning rate 0.0030000 \n",
      "Step: 150/217, accuracy0.117, loss3.301, learning rate 0.0030000 \n",
      "Step: 155/217, accuracy0.129, loss3.307, learning rate 0.0030000 \n",
      "Step: 160/217, accuracy0.148, loss3.271, learning rate 0.0030000 \n",
      "Step: 165/217, accuracy0.125, loss3.298, learning rate 0.0030000 \n",
      "Step: 170/217, accuracy0.145, loss3.262, learning rate 0.0030000 \n",
      "Step: 175/217, accuracy0.090, loss3.419, learning rate 0.0030000 \n",
      "Step: 180/217, accuracy0.129, loss3.372, learning rate 0.0030000 \n",
      "Step: 185/217, accuracy0.074, loss3.408, learning rate 0.0030000 \n",
      "Step: 190/217, accuracy0.066, loss3.461, learning rate 0.0030000 \n",
      "Step: 195/217, accuracy0.121, loss3.329, learning rate 0.0030000 \n",
      "Step: 200/217, accuracy0.105, loss3.353, learning rate 0.0030000 \n",
      "Step: 205/217, accuracy0.086, loss3.415, learning rate 0.0030000 \n",
      "Step: 210/217, accuracy0.129, loss3.334, learning rate 0.0030000 \n",
      "Step: 215/217, accuracy0.152, loss3.314, learning rate 0.0030000 \n",
      "Step: 216/217, accuracy0.161, loss3.281, learning rate 0.0030000 \n",
      "Epoch: 6/100, accuracy0.122, loss3.351, learning rate 0.003\n",
      "Estimated reamining runtime: 6 days, 12:04:23.037654\n",
      "--Validation--\n",
      "Validation : Accuracy: 0.133, Loss: 3.302\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Plant Leaf Disease\")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=256, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(test_data, batch_size=256, shuffle=True)\n",
    "\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param('framework', 'homebrew')\n",
    "    mlflow.log_param('data_split', '90/10')\n",
    "    mlflow.log_param('type', 'Basic_CNN_LeNet')\n",
    "    mlflow.log_param('trainable_parameters', mdl.get_parameters_())\n",
    "    mlflow.log_params(config)\n",
    "    mdl.train_with_loader(train_loader, epochs=config['max_epochs'], validation_loader=validation_loader, cls_count=39, log_freq=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
