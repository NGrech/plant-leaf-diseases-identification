{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29ee38e8",
   "metadata": {},
   "source": [
    "# Implementation of Basic Homebrew CNN (greyscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b2250c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'model' from '..\\\\src\\\\model.py'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# General imports \n",
    "import sys\n",
    "import os \n",
    "sys.path.insert(1, os.path.join(os.pardir, 'src'))\n",
    "from itertools import product\n",
    "\n",
    "# Data imports\n",
    "import torch\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Homebrew imports \n",
    "import model\n",
    "from utils import one_hot_encode_index\n",
    "from optimizers import Adam\n",
    "from activations import Softmax, ReLU\n",
    "from layers import Dropout, LinearLayer, ConvolutionLayer, PoolingLayer, FlattenLayer\n",
    "from loss import CategoricalCrossEntropyLoss\n",
    "\n",
    "## TESTING \n",
    "import importlib\n",
    "importlib.reload(model)\n",
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dbb6cc",
   "metadata": {},
   "source": [
    "## Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d69b9a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(32),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.Grayscale(num_output_channels=1),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.5],[0.5])\n",
    "                                      ])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(33),\n",
    "                                      transforms.CenterCrop(32),\n",
    "                                      transforms.Grayscale(num_output_channels=1),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.5],[0.5])\n",
    "                                    ])\n",
    "\n",
    "# setting up data loaders\n",
    "data_dir = os.path.join(os.pardir, 'data', 'Plant_leave_diseases_32')\n",
    "\n",
    "train_data = datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(os.path.join(data_dir, 'validation'), transform=test_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51af43ca",
   "metadata": {},
   "source": [
    "### Train config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d59977a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs \n",
    "config = {\n",
    "    'max_epochs': 10,\n",
    "    'learning_rate': 0.003,\n",
    "    'resolution': 32,\n",
    "    'name': 'Basic_CNN_greyscale_module_homebrew'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ce71e6",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a3b2d3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Architecture: \n",
      "\t (0): ConvolutionLayer (Trainable: False)\n",
      "\t (1): ReLU (Trainable: False)\n",
      "\t (2): PoolingLayer (Trainable: False)\n",
      "\t (3): FlattenLayer (Trainable: False)\n",
      "\t (4): LinearLayer (Trainable: True)\n",
      "\t (5): ReLU (Trainable: False)\n",
      "\t (6): LinearLayer (Trainable: True)\n",
      "\t (7): ReLU (Trainable: False)\n",
      "\t (8): LinearLayer (Trainable: True)\n",
      "\t (9): Softmax (Trainable: False)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mdl = model.Model(Adam(learning_rate=config['learning_rate']),\n",
    "                      CategoricalCrossEntropyLoss())\n",
    "\n",
    "# Config early stop \n",
    "mdl.add_early_stop(5)\n",
    "\n",
    "mdl.set_save_config(model_name=config['name'], save_path=os.path.join(os.pardir, 'model'))\n",
    "\n",
    "# Defining architecture \n",
    "\n",
    "mdl.set_sequence([\n",
    "                    ConvolutionLayer(1, 6, 3),\n",
    "                    ReLU(),\n",
    "                    PoolingLayer(6, 2),\n",
    "                    FlattenLayer(),\n",
    "                    LinearLayer(1350, 784),\n",
    "                    ReLU(),\n",
    "                    LinearLayer(784, 128),\n",
    "                    ReLU(),\n",
    "                    LinearLayer(128, 39),\n",
    "                    Softmax()\n",
    "                ])\n",
    "print(mdl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb41934",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "14df8745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch: 1 ===\n",
      "Step: 0/433, accuracy0.047, loss3.659, learning rate 0.0030000 \n",
      "Step: 5/433, accuracy0.086, loss3.569, learning rate 0.0030000 \n",
      "Step: 10/433, accuracy0.062, loss3.650, learning rate 0.0030000 \n",
      "Step: 15/433, accuracy0.070, loss3.590, learning rate 0.0030000 \n",
      "Step: 20/433, accuracy0.125, loss3.559, learning rate 0.0030000 \n",
      "Step: 25/433, accuracy0.102, loss3.402, learning rate 0.0030000 \n",
      "Step: 30/433, accuracy0.086, loss3.482, learning rate 0.0030000 \n",
      "Step: 35/433, accuracy0.109, loss3.395, learning rate 0.0030000 \n",
      "Step: 40/433, accuracy0.102, loss3.322, learning rate 0.0030000 \n",
      "Step: 45/433, accuracy0.141, loss3.386, learning rate 0.0030000 \n",
      "Step: 50/433, accuracy0.117, loss3.332, learning rate 0.0030000 \n",
      "Step: 55/433, accuracy0.133, loss3.226, learning rate 0.0030000 \n",
      "Step: 60/433, accuracy0.109, loss3.245, learning rate 0.0030000 \n",
      "Step: 65/433, accuracy0.180, loss3.254, learning rate 0.0030000 \n",
      "Step: 70/433, accuracy0.156, loss3.144, learning rate 0.0030000 \n",
      "Step: 75/433, accuracy0.172, loss3.250, learning rate 0.0030000 \n",
      "Step: 80/433, accuracy0.195, loss3.057, learning rate 0.0030000 \n",
      "Step: 85/433, accuracy0.227, loss3.003, learning rate 0.0030000 \n",
      "Step: 90/433, accuracy0.188, loss3.311, learning rate 0.0030000 \n",
      "Step: 95/433, accuracy0.148, loss3.155, learning rate 0.0030000 \n",
      "Step: 100/433, accuracy0.172, loss3.249, learning rate 0.0030000 \n",
      "Step: 105/433, accuracy0.219, loss3.049, learning rate 0.0030000 \n",
      "Step: 110/433, accuracy0.125, loss3.397, learning rate 0.0030000 \n",
      "Step: 115/433, accuracy0.164, loss3.175, learning rate 0.0030000 \n",
      "Step: 120/433, accuracy0.195, loss3.121, learning rate 0.0030000 \n",
      "Step: 125/433, accuracy0.172, loss3.195, learning rate 0.0030000 \n",
      "Step: 130/433, accuracy0.250, loss3.164, learning rate 0.0030000 \n",
      "Step: 135/433, accuracy0.180, loss3.079, learning rate 0.0030000 \n",
      "Step: 140/433, accuracy0.148, loss3.208, learning rate 0.0030000 \n",
      "Step: 145/433, accuracy0.227, loss3.274, learning rate 0.0030000 \n",
      "Step: 150/433, accuracy0.164, loss3.231, learning rate 0.0030000 \n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Plant Leaf Disease\")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(test_data, batch_size=128, shuffle=True)\n",
    "\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param('framework', 'homebrew')\n",
    "    mlflow.log_param('data_split', '90/10')\n",
    "    mlflow.log_param('type', 'Basic_CNN_greyscale')\n",
    "    mlflow.log_params(config)\n",
    "    mdl.train_with_loader(train_loader, epochs=config['max_epochs'], validation_loader=validation_loader, cls_count=39, log_freq=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae5f745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 1350)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.layers[3].output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4649471e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
