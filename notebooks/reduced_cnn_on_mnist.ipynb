{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import urllib.request\n",
    "import cv2\n",
    "import mlflow\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import mlflow\n",
    "\n",
    "from zipfile import ZipFile\n",
    "import sys\n",
    "# sys.path.append(r'../src')\n",
    "import importlib\n",
    "\n",
    "import model\n",
    "import layers\n",
    "import activations\n",
    "\n",
    "from utils import one_hot_encode_index\n",
    "from optimizers import Adam\n",
    "from activations import Softmax, ReLU\n",
    "from layers import Dropout, LinearLayer, ConvolutionLayer, PoolingLayer, FlattenLayer\n",
    "from loss import CategoricalCrossEntropyLoss\n",
    "\n",
    "def nsgpmnet_reloads():\n",
    "\n",
    "    importlib.reload(model)\n",
    "    importlib.reload(layers)\n",
    "    importlib.reload(activations)\n",
    "\n",
    "nsgpmnet_reloads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading MNIST-fashion-data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads a MNIST dataset\n",
    "def load_mnist_dataset(dataset, path):\n",
    "    # Scan all the directories and create a list of labels\n",
    "    labels = os.listdir(os.path.join(path, dataset))\n",
    "    # Create lists for samples and labels\n",
    "    X = []\n",
    "    y = []\n",
    "    # For each label folder\n",
    "    for label in labels:\n",
    "        # And for each image in given folder\n",
    "        for file in os.listdir(os.path.join(path, dataset, label)):\n",
    "            # Read the image\n",
    "            image = cv2.imread(os.path.join(path, dataset, label, file), cv2.IMREAD_UNCHANGED)\n",
    "            # And append it and a label to the lists\n",
    "            X.append(image)\n",
    "            y.append(label)\n",
    "    # Convert the data to proper numpy arrays and return\n",
    "    return np.array(X), np.array(y).astype('uint8')\n",
    "\n",
    "\n",
    "def create_data_mnist(path):\n",
    "    # Load both sets separately\n",
    "    X, y = load_mnist_dataset('train', path)\n",
    "    X_test, y_test = load_mnist_dataset('test', path)\n",
    "    y = one_hot_encode_index(y, 10)\n",
    "    y_test = one_hot_encode_index(y_test, 10)\n",
    "    \n",
    "    # And return all the data\n",
    "    return X, y, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path0 = '/Users/petermagnusson/Documents/data/courses to study/malmoÌˆ universitet/3 ht2021/120p 2yrs MSc copmuter science - applied data science/course AI for data science/project/leaf/data/fashion_mnist_images'\n",
    "\n",
    "X, y, X_test, y_test = create_data_mnist(path0)\n",
    "\n",
    "y_flat = y.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handy print fuction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_info(a):\n",
    "    print('shapes for inputs and outputs:')\n",
    "    print(a.shape)\n",
    "    print('(min, max) for inputs and outputs:')\n",
    "    print(np.min(a), np.max(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle Training data - on initial loaded data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = np.array(range(X.shape[0]))\n",
    "np.random.shuffle(keys)\n",
    "X = X[keys]\n",
    "y = y[keys]\n",
    "y_flat = y_flat[keys]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping data for cnn-model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_channles(v):\n",
    "    return np.expand_dims(v, axis=1)\n",
    "\n",
    "X_chns = add_channles(X)\n",
    "X_chns_test = add_channles(X_test)\n",
    "\n",
    "# Optional truncation to fewer images for integration and timing testing.\n",
    "tval = 59904 # 200, 59968 (for batch_size=64), 59904 (for batch_size=128) 9984, 1024, 2048\n",
    "X_chns = X_chns[:tval, :, :]\n",
    "X_chns_test = X_chns_test[:tval, :, :]\n",
    "\n",
    "# print_info(X)\n",
    "# print_info(X_chns)\n",
    "# print_info(X_chns_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling between -1 and 1 - cnn-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_img(v):\n",
    "    return (v - 127.5) /127.5\n",
    "\n",
    "X_chns = scale_img(X_chns)\n",
    "X_chns_test = scale_img(X_chns_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle Training data - cnn-model - after truncation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = np.array(range(X_chns.shape[0]))\n",
    "np.random.shuffle(keys)\n",
    "X_chns = X_chns[keys]\n",
    "y = y[keys]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a reduced cnn-model sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cce_loss = CategoricalCrossEntropyLoss()\n",
    "optimizer = Adam(decay=5e-5)\n",
    "my_model = model.Model(optimizer, cce_loss)\n",
    "\n",
    "my_model.set_sequence([\n",
    "                ConvolutionLayer(1, 1, 3),\n",
    "                FlattenLayer(),\n",
    "                LinearLayer(676, 128),\n",
    "                ReLU(),\n",
    "                Dropout(0.5),\n",
    "                LinearLayer(128, 128),\n",
    "                ReLU(),\n",
    "                LinearLayer(128, 10),\n",
    "                Softmax()\n",
    "            ])\n",
    "\n",
    "# Setting the model save path:\n",
    "path1 = '/Users/petermagnusson/VisualStudioCodeProjects/saved_models/model1'\n",
    "my_model.set_save_config(model_name='cnn_9_0', save_path=path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_info(X)\n",
    "print_info(X_chns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with the reduced cnn-model, optional monitoring with MLflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch: 1 ===\n",
      "Step: 0/468, accuracy0.094, loss2.302, learning rate 0.0010000 \n",
      "Step: 100/468, accuracy0.672, loss0.879, learning rate 0.0009950 \n",
      "Step: 200/468, accuracy0.703, loss0.920, learning rate 0.0009901 \n",
      "Step: 300/468, accuracy0.766, loss0.840, learning rate 0.0009852 \n",
      "Step: 400/468, accuracy0.797, loss0.495, learning rate 0.0009804 \n",
      "Step: 467/468, accuracy0.703, loss0.882, learning rate 0.0009772 \n",
      "Epoch: 1/10, accuracy0.697, loss0.964, learning rate 0.001\n",
      "--Validation--\n",
      "Validation : Accuracy: 0.825, Loss: 0.494\n",
      "=== Epoch: 2 ===\n",
      "Step: 0/468, accuracy0.820, loss0.503, learning rate 0.0009771 \n",
      "Step: 100/468, accuracy0.680, loss1.772, learning rate 0.0009724 \n",
      "Step: 200/468, accuracy0.641, loss0.948, learning rate 0.0009677 \n",
      "Step: 300/468, accuracy0.695, loss0.877, learning rate 0.0009630 \n",
      "Step: 400/468, accuracy0.797, loss0.583, learning rate 0.0009584 \n",
      "Step: 467/468, accuracy0.688, loss1.043, learning rate 0.0009553 \n",
      "Epoch: 2/10, accuracy0.770, loss0.695, learning rate 0.001\n",
      "--Validation--\n",
      "New best model ... saving\n",
      "Validation : Accuracy: 0.832, Loss: 0.477\n",
      "=== Epoch: 3 ===\n",
      "Step: 0/468, accuracy0.852, loss0.434, learning rate 0.0009553 \n",
      "Step: 100/468, accuracy0.805, loss0.674, learning rate 0.0009508 \n",
      "Step: 200/468, accuracy0.766, loss0.537, learning rate 0.0009463 \n",
      "Step: 300/468, accuracy0.773, loss0.627, learning rate 0.0009418 \n",
      "Step: 400/468, accuracy0.828, loss0.488, learning rate 0.0009374 \n",
      "Step: 467/468, accuracy0.734, loss0.704, learning rate 0.0009344 \n",
      "Epoch: 3/10, accuracy0.814, loss0.528, learning rate 0.001\n",
      "--Validation--\n",
      "New best model ... saving\n",
      "Validation : Accuracy: 0.847, Loss: 0.423\n",
      "=== Epoch: 4 ===\n",
      "Step: 0/468, accuracy0.844, loss0.382, learning rate 0.0009344 \n",
      "Step: 100/468, accuracy0.844, loss0.488, learning rate 0.0009301 \n",
      "Step: 200/468, accuracy0.750, loss0.561, learning rate 0.0009258 \n",
      "Step: 300/468, accuracy0.797, loss0.557, learning rate 0.0009215 \n",
      "Step: 400/468, accuracy0.836, loss0.447, learning rate 0.0009173 \n",
      "Step: 467/468, accuracy0.766, loss0.623, learning rate 0.0009145 \n",
      "Epoch: 4/10, accuracy0.825, loss0.485, learning rate 0.001\n",
      "--Validation--\n",
      "New best model ... saving\n",
      "Validation : Accuracy: 0.851, Loss: 0.416\n",
      "=== Epoch: 5 ===\n",
      "Step: 0/468, accuracy0.852, loss0.382, learning rate 0.0009144 \n",
      "Step: 100/468, accuracy0.820, loss0.558, learning rate 0.0009102 \n",
      "Step: 200/468, accuracy0.703, loss0.914, learning rate 0.0009061 \n",
      "Step: 300/468, accuracy0.797, loss0.646, learning rate 0.0009020 \n",
      "Step: 400/468, accuracy0.836, loss0.450, learning rate 0.0008980 \n",
      "Step: 467/468, accuracy0.750, loss0.649, learning rate 0.0008953 \n",
      "Epoch: 5/10, accuracy0.787, loss0.740, learning rate 0.001\n",
      "--Validation--\n",
      "Validation : Accuracy: 0.834, Loss: 0.470\n",
      "=== Epoch: 6 ===\n",
      "Step: 0/468, accuracy0.875, loss0.488, learning rate 0.0008953 \n",
      "Step: 100/468, accuracy0.820, loss0.609, learning rate 0.0008913 \n",
      "Step: 200/468, accuracy0.805, loss0.491, learning rate 0.0008873 \n",
      "Step: 300/468, accuracy0.789, loss0.556, learning rate 0.0008834 \n",
      "Step: 400/468, accuracy0.820, loss0.463, learning rate 0.0008795 \n",
      "Step: 467/468, accuracy0.758, loss0.720, learning rate 0.0008769 \n",
      "Epoch: 6/10, accuracy0.823, loss0.506, learning rate 0.001\n",
      "--Validation--\n",
      "Validation : Accuracy: 0.854, Loss: 0.423\n",
      "=== Epoch: 7 ===\n",
      "Step: 0/468, accuracy0.844, loss0.390, learning rate 0.0008769 \n",
      "Step: 100/468, accuracy0.828, loss0.472, learning rate 0.0008731 \n",
      "Step: 200/468, accuracy0.820, loss0.468, learning rate 0.0008693 \n",
      "Step: 300/468, accuracy0.836, loss0.415, learning rate 0.0008655 \n",
      "Step: 400/468, accuracy0.836, loss0.442, learning rate 0.0008618 \n",
      "Step: 467/468, accuracy0.773, loss0.613, learning rate 0.0008593 \n",
      "Epoch: 7/10, accuracy0.837, loss0.459, learning rate 0.001\n",
      "--Validation--\n",
      "New best model ... saving\n",
      "Validation : Accuracy: 0.852, Loss: 0.411\n",
      "=== Epoch: 8 ===\n",
      "Step: 0/468, accuracy0.828, loss0.377, learning rate 0.0008593 \n",
      "Step: 100/468, accuracy0.828, loss0.556, learning rate 0.0008556 \n",
      "Step: 200/468, accuracy0.844, loss0.517, learning rate 0.0008519 \n",
      "Step: 300/468, accuracy0.789, loss0.484, learning rate 0.0008483 \n",
      "Step: 400/468, accuracy0.859, loss0.348, learning rate 0.0008447 \n",
      "Step: 467/468, accuracy0.758, loss0.592, learning rate 0.0008424 \n",
      "Epoch: 8/10, accuracy0.847, loss0.427, learning rate 0.001\n",
      "--Validation--\n",
      "New best model ... saving\n",
      "Validation : Accuracy: 0.857, Loss: 0.396\n",
      "=== Epoch: 9 ===\n",
      "Step: 0/468, accuracy0.906, loss0.325, learning rate 0.0008423 \n",
      "Step: 100/468, accuracy0.883, loss0.365, learning rate 0.0008388 \n",
      "Step: 200/468, accuracy0.883, loss0.403, learning rate 0.0008353 \n",
      "Step: 300/468, accuracy0.820, loss0.438, learning rate 0.0008318 \n",
      "Step: 400/468, accuracy0.844, loss0.372, learning rate 0.0008284 \n",
      "Step: 467/468, accuracy0.703, loss0.648, learning rate 0.0008261 \n",
      "Epoch: 9/10, accuracy0.851, loss0.410, learning rate 0.001\n",
      "--Validation--\n",
      "Validation : Accuracy: 0.859, Loss: 0.402\n",
      "=== Epoch: 10 ===\n",
      "Step: 0/468, accuracy0.844, loss0.368, learning rate 0.0008260 \n",
      "Step: 100/468, accuracy0.883, loss0.386, learning rate 0.0008226 \n",
      "Step: 200/468, accuracy0.859, loss0.384, learning rate 0.0008193 \n",
      "Step: 300/468, accuracy0.820, loss0.511, learning rate 0.0008159 \n",
      "Step: 400/468, accuracy0.875, loss0.343, learning rate 0.0008126 \n",
      "Step: 467/468, accuracy0.773, loss0.633, learning rate 0.0008104 \n",
      "Epoch: 10/10, accuracy0.856, loss0.397, learning rate 0.001\n",
      "--Validation--\n",
      "New best model ... saving\n",
      "Validation : Accuracy: 0.863, Loss: 0.391\n",
      "Took 77.69471001625061\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "mlflow.set_experiment(experiment_name='MNIST Fashion reduced conv')\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# my_model.train(X_chns, y, epochs=1, batch_size=8, log_freq=8, validation=(X_chns_test, y_test))\n",
    "my_model.train(X_chns, y, epochs=10, batch_size=128, log_freq=100, validation=(X_chns_test, y_test))\n",
    "\n",
    "t_d0 = time.time() - t0\n",
    "print('Took {}'.format(t_d0))\n",
    "\n",
    "# with mlflow.start_run():\n",
    "#     my_model.train(X_chns, y, epochs=10, batch_size=128, log_freq=100, validation=(X_chns_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the cnn-model with the test-set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation : Accuracy: 0.863, Loss: 0.394\n"
     ]
    }
   ],
   "source": [
    "my_model.evaluate(X_chns_test, y_test, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x504 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(7.00, 7.00), ncols=2, nrows=2)\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.imshow(c[0, 0, :, :], cmap=cm.gray)\n",
    "ax[0, 0].imshow(X_chns[int(np.random.randint(0, 200)), 0, :, :], cmap=cm.gray)\n",
    "ax[0, 1].imshow(X_chns[123, 0, :, :], cmap=cm.gray)\n",
    "# ax[1, 0].imshow(pool1.dinputs[0, 0, :, :], cmap=cm.gray)\n",
    "# ax[1, 1].imshow(conv1.outputs[0, 1, :, :], cmap=cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retreive org. data and flatten for ffnn model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(v):\n",
    "    return v.reshape(v.shape[0], -1)\n",
    "\n",
    "X_flat = vectorize(X)\n",
    "X_flat_test = vectorize(X_test)\n",
    "\n",
    "# print_info(X)\n",
    "# print_info(X_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trucate for ffnn model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truncate to fewer images for integration and timing testing.\n",
    "tval = 9984 # 200, 59968, 9984, 1024, 2048\n",
    "X_flat = X_flat[:tval, :]\n",
    "X_flat_test = X_flat_test[:tval, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling between -1 and 1 - ffnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_img(v):\n",
    "    return (v - 127.5) /127.5\n",
    "\n",
    "X_flat = scale_img(X_flat)\n",
    "X_flat_test = scale_img(X_flat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle training data - ffnn model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = np.array(range(X_flat.shape[0]))\n",
    "np.random.shuffle(keys)\n",
    "X_flat = X_flat[keys]\n",
    "y_flat = y_flat[keys]\n",
    "\n",
    "# print_info(X)\n",
    "# print_info(X_flat)\n",
    "# print_info(y_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a sequence for ffnn model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cce_loss = CategoricalCrossEntropyLoss()\n",
    "optimizer = Adam(decay=5e-5)\n",
    "\n",
    "naive_model = model.Model(optimizer, cce_loss)\n",
    "\n",
    "naive_model.set_sequence([\n",
    "                LinearLayer(X_flat.shape[1], 128),\n",
    "                ReLU(),\n",
    "                Dropout(0.5),\n",
    "                LinearLayer(128, 128),\n",
    "                ReLU(),\n",
    "                LinearLayer(128, 10),\n",
    "                Softmax()\n",
    "            ])\n",
    "\n",
    "# Setting the model save path:\n",
    "path1 = '/Users/petermagnusson/VisualStudioCodeProjects/saved_models/model0'\n",
    "naive_model.set_save_config(model_name='ffnn_0', save_path=path1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with the ffnn model, optional monitoring with MLflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch: 1 ===\n",
      "Step: 0/469, accuracy0.086, loss3.606, learning rate 0.0010000 \n",
      "Step: 100/469, accuracy0.750, loss0.704, learning rate 0.0009950 \n",
      "Step: 200/469, accuracy0.758, loss0.575, learning rate 0.0009901 \n",
      "Step: 300/469, accuracy0.781, loss0.550, learning rate 0.0009852 \n",
      "Step: 400/469, accuracy0.781, loss0.538, learning rate 0.0009804 \n",
      "Step: 468/469, accuracy0.771, loss0.604, learning rate 0.0009771 \n",
      "Epoch: 1/10, accuracy0.743, loss0.713, learning rate 0.001\n",
      "--Validation--\n",
      "Validation : Accuracy: 0.826, Loss: 0.478\n",
      "=== Epoch: 2 ===\n",
      "Step: 0/469, accuracy0.789, loss0.516, learning rate 0.0009771 \n",
      "Step: 100/469, accuracy0.812, loss0.483, learning rate 0.0009723 \n",
      "Step: 200/469, accuracy0.789, loss0.468, learning rate 0.0009676 \n",
      "Step: 300/469, accuracy0.789, loss0.532, learning rate 0.0009630 \n",
      "Step: 400/469, accuracy0.820, loss0.421, learning rate 0.0009584 \n",
      "Step: 468/469, accuracy0.792, loss0.592, learning rate 0.0009552 \n",
      "Epoch: 2/10, accuracy0.814, loss0.515, learning rate 0.001\n",
      "--Validation--\n",
      "New best model ... saving\n",
      "Validation : Accuracy: 0.835, Loss: 0.448\n",
      "=== Epoch: 3 ===\n",
      "Step: 0/469, accuracy0.812, loss0.483, learning rate 0.0009552 \n",
      "Step: 100/469, accuracy0.844, loss0.390, learning rate 0.0009507 \n",
      "Step: 200/469, accuracy0.844, loss0.420, learning rate 0.0009462 \n",
      "Step: 300/469, accuracy0.836, loss0.421, learning rate 0.0009417 \n",
      "Step: 400/469, accuracy0.836, loss0.363, learning rate 0.0009373 \n",
      "Step: 468/469, accuracy0.792, loss0.549, learning rate 0.0009343 \n",
      "Epoch: 3/10, accuracy0.827, loss0.476, learning rate 0.001\n",
      "--Validation--\n",
      "New best model ... saving\n",
      "Validation : Accuracy: 0.835, Loss: 0.432\n",
      "=== Epoch: 4 ===\n",
      "Step: 0/469, accuracy0.828, loss0.465, learning rate 0.0009343 \n",
      "Step: 100/469, accuracy0.820, loss0.450, learning rate 0.0009299 \n",
      "Step: 200/469, accuracy0.875, loss0.351, learning rate 0.0009256 \n",
      "Step: 300/469, accuracy0.867, loss0.413, learning rate 0.0009214 \n",
      "Step: 400/469, accuracy0.836, loss0.400, learning rate 0.0009171 \n",
      "Step: 468/469, accuracy0.833, loss0.492, learning rate 0.0009143 \n",
      "Epoch: 4/10, accuracy0.837, loss0.453, learning rate 0.001\n",
      "--Validation--\n",
      "New best model ... saving\n",
      "Validation : Accuracy: 0.844, Loss: 0.421\n",
      "=== Epoch: 5 ===\n",
      "Step: 0/469, accuracy0.828, loss0.484, learning rate 0.0009142 \n",
      "Step: 100/469, accuracy0.844, loss0.392, learning rate 0.0009101 \n",
      "Step: 200/469, accuracy0.906, loss0.302, learning rate 0.0009060 \n",
      "Step: 300/469, accuracy0.844, loss0.422, learning rate 0.0009019 \n",
      "Step: 400/469, accuracy0.828, loss0.407, learning rate 0.0008978 \n",
      "Step: 468/469, accuracy0.823, loss0.401, learning rate 0.0008951 \n",
      "Epoch: 5/10, accuracy0.845, loss0.432, learning rate 0.001\n",
      "--Validation--\n",
      "New best model ... saving\n",
      "Validation : Accuracy: 0.846, Loss: 0.407\n",
      "=== Epoch: 6 ===\n",
      "Step: 0/469, accuracy0.820, loss0.474, learning rate 0.0008951 \n",
      "Step: 100/469, accuracy0.883, loss0.364, learning rate 0.0008911 \n",
      "Step: 200/469, accuracy0.922, loss0.305, learning rate 0.0008871 \n",
      "Step: 300/469, accuracy0.844, loss0.401, learning rate 0.0008832 \n",
      "Step: 400/469, accuracy0.898, loss0.306, learning rate 0.0008793 \n",
      "Step: 468/469, accuracy0.812, loss0.462, learning rate 0.0008767 \n",
      "Epoch: 6/10, accuracy0.847, loss0.418, learning rate 0.001\n",
      "--Validation--\n",
      "New best model ... saving\n",
      "Validation : Accuracy: 0.856, Loss: 0.399\n",
      "=== Epoch: 7 ===\n",
      "Step: 0/469, accuracy0.844, loss0.405, learning rate 0.0008767 \n",
      "Step: 100/469, accuracy0.875, loss0.438, learning rate 0.0008728 \n",
      "Step: 200/469, accuracy0.906, loss0.273, learning rate 0.0008690 \n",
      "Step: 300/469, accuracy0.836, loss0.481, learning rate 0.0008653 \n",
      "Step: 400/469, accuracy0.898, loss0.368, learning rate 0.0008615 \n",
      "Step: 468/469, accuracy0.833, loss0.397, learning rate 0.0008590 \n",
      "Epoch: 7/10, accuracy0.853, loss0.408, learning rate 0.001\n",
      "--Validation--\n",
      "New best model ... saving\n",
      "Validation : Accuracy: 0.861, Loss: 0.383\n",
      "=== Epoch: 8 ===\n",
      "Step: 0/469, accuracy0.844, loss0.422, learning rate 0.0008590 \n",
      "Step: 100/469, accuracy0.875, loss0.362, learning rate 0.0008553 \n",
      "Step: 200/469, accuracy0.891, loss0.282, learning rate 0.0008517 \n",
      "Step: 300/469, accuracy0.867, loss0.422, learning rate 0.0008481 \n",
      "Step: 400/469, accuracy0.883, loss0.320, learning rate 0.0008445 \n",
      "Step: 468/469, accuracy0.802, loss0.394, learning rate 0.0008421 \n",
      "Epoch: 8/10, accuracy0.856, loss0.394, learning rate 0.001\n",
      "--Validation--\n",
      "New best model ... saving\n",
      "Validation : Accuracy: 0.862, Loss: 0.378\n",
      "=== Epoch: 9 ===\n",
      "Step: 0/469, accuracy0.844, loss0.394, learning rate 0.0008420 \n",
      "Step: 100/469, accuracy0.883, loss0.376, learning rate 0.0008385 \n",
      "Step: 200/469, accuracy0.891, loss0.310, learning rate 0.0008350 \n",
      "Step: 300/469, accuracy0.883, loss0.402, learning rate 0.0008315 \n",
      "Step: 400/469, accuracy0.898, loss0.291, learning rate 0.0008281 \n",
      "Step: 468/469, accuracy0.854, loss0.337, learning rate 0.0008258 \n",
      "Epoch: 9/10, accuracy0.856, loss0.390, learning rate 0.001\n",
      "--Validation--\n",
      "New best model ... saving\n",
      "Validation : Accuracy: 0.868, Loss: 0.366\n",
      "=== Epoch: 10 ===\n",
      "Step: 0/469, accuracy0.836, loss0.390, learning rate 0.0008257 \n",
      "Step: 100/469, accuracy0.891, loss0.377, learning rate 0.0008223 \n",
      "Step: 200/469, accuracy0.891, loss0.268, learning rate 0.0008190 \n",
      "Step: 300/469, accuracy0.867, loss0.362, learning rate 0.0008156 \n",
      "Step: 400/469, accuracy0.875, loss0.285, learning rate 0.0008123 \n",
      "Step: 468/469, accuracy0.844, loss0.387, learning rate 0.0008101 \n",
      "Epoch: 10/10, accuracy0.859, loss0.380, learning rate 0.001\n",
      "--Validation--\n",
      "Validation : Accuracy: 0.863, Loss: 0.381\n",
      "Took 17.058357000350952\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "mlflow.set_experiment(experiment_name='Naive Model')\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# naive_model.train(X_flat, y_flat, epochs=1, batch_size=8, log_freq=32, validation=(X_flat_test, y_test))\n",
    "naive_model.train(X_flat, y_flat, epochs=10, batch_size=128, log_freq=100, validation=(X_flat_test, y_test))\n",
    "\n",
    "t_d0 = time.time() - t0\n",
    "print('Took {}'.format(t_d0))\n",
    "\n",
    "# with mlflow.start_run():\n",
    "#     naive_model.train(X_flat, y_flat, epochs=10, batch_size=128, log_freq=100, validation=(X_flat_test, y_test))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d53c06ab4573055b295bcdfb3b25bc2da21e5ae576a05184a9c53fc2168185ab"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('plant-leaf-diseases-identification-CBiGMIHu-py3.8': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
