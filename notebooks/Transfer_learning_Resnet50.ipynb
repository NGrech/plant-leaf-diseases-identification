{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import mlflow\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from collections import OrderedDict\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning with Resnet 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Resnet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = models.resnet50(pretrained=True)\n",
    "\n",
    "# Freezing the paramiters of the layers we do not want to train\n",
    "for parameters in mdl.parameters():\n",
    "    parameters.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating Classification layer \n",
    "_inputs = mdl.fc.in_features\n",
    "\n",
    "mdl.fc = nn.Sequential(OrderedDict([\n",
    "    ('fc1', nn.Linear(_inputs, 500)),\n",
    "    ('relu', nn.ReLU()),\n",
    "    ('dropout', nn.Dropout(0.2)),\n",
    "    ('fc2', nn.Linear(500, 39)),\n",
    "    ('output', nn.LogSoftmax(dim=1))\n",
    "]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, validation_loader, config, n_epochs=10, stopping_treshold=None):\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        print('CUDA is available!  Training on GPU ...')\n",
    "        model.cuda()\n",
    "\n",
    "\n",
    "    # Loss and optimizer setup \n",
    "    criterion = nn.NLLLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "\n",
    "    # Setting minimum validation loss to inf\n",
    "    validation_loss_minimum = np.Inf \n",
    "    train_loss_history = []\n",
    "    validation_loss_history = []\n",
    "\n",
    "    for epoch in range(1, n_epochs +1):\n",
    "\n",
    "        training_loss = 0.0\n",
    "        validation_loss = 0.0\n",
    "\n",
    "        # Training loop\n",
    "        training_accuracies = []\n",
    "        for X, y in train_loader:\n",
    "            \n",
    "            # Moving data to gpu if using \n",
    "            if torch.cuda.is_available():\n",
    "                X, y = X.cuda(), y.cuda()\n",
    "            \n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(X)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, y)\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # update training loss\n",
    "            training_loss += loss.item()*X.size(0)\n",
    "\n",
    "            # calculating accuracy\n",
    "            ps = torch.exp(output)\n",
    "            top_p, top_class = ps.topk(1, dim=1)\n",
    "            equals = top_class == y.view(*top_class.shape)\n",
    "            training_accuracies.append(torch.mean(equals.type(torch.FloatTensor)).item())\n",
    "\n",
    "        # Validation Loop\n",
    "        with torch.no_grad():\n",
    "            accuracies = []\n",
    "            for X, y in validation_loader:\n",
    "\n",
    "                # Moving data to gpu if using \n",
    "                if torch.cuda.is_available():\n",
    "                    X, y = X.cuda(), y.cuda()\n",
    "                # forward pass: compute predicted outputs by passing inputs to the model\n",
    "                output = model(X)\n",
    "                # calculate the batch loss\n",
    "                loss = criterion(output, y)\n",
    "                # update validation loss\n",
    "                validation_loss += loss.item()*X.size(0)\n",
    "\n",
    "                # calculating accuracy\n",
    "                ps = torch.exp(output)\n",
    "                top_p, top_class = ps.topk(1, dim=1)\n",
    "                equals = top_class == y.view(*top_class.shape)\n",
    "                accuracies.append(torch.mean(equals.type(torch.FloatTensor)).item())\n",
    "                \n",
    "        # Mean loss \n",
    "        mean_training_loss = training_loss/len(train_loader.sampler)\n",
    "        mean_validation_loss = validation_loss/len(validation_loader.sampler)\n",
    "        mean_train_accuracy = sum(training_accuracies)/len(training_accuracies)\n",
    "        mean_accuracy = sum(accuracies)/len(accuracies)\n",
    "        train_loss_history.append(mean_training_loss)\n",
    "        validation_loss_history.append(mean_validation_loss)\n",
    "\n",
    "        # Printing epoch stats\n",
    "        print(f'Epoch: {epoch}/{n_epochs}, ' +\\\n",
    "              f'Training Loss: {mean_training_loss:.3f}, '+\\\n",
    "              f'Train accuracy {mean_train_accuracy:.3f} ' +\\\n",
    "              f'Validation Loss: {mean_validation_loss:.3f}, '+\\\n",
    "              f'Validation accuracy {mean_accuracy:.3f}')\n",
    "\n",
    "        # logging with mlflow \n",
    "        if mlflow.active_run():\n",
    "            mlflow.log_metric('loss', mean_training_loss, step=epoch)\n",
    "            mlflow.log_metric('accuracy', mean_train_accuracy, step=epoch)\n",
    "            mlflow.log_metric('validation_accuracy', mean_accuracy, step=epoch)\n",
    "            mlflow.log_metric('validation_loss', mean_validation_loss, step=epoch)\n",
    "\n",
    "        # Testing for early stopping\n",
    "        # Testing for early stopping\n",
    "        if stopping_treshold:\n",
    "            if mean_validation_loss < validation_loss_minimum:\n",
    "                validation_loss_minimum = mean_validation_loss\n",
    "                print('New minimum validation loss (saving model)')\n",
    "                save_pth = os.path.join('models',f'{config[\"name\"]}.pt')\n",
    "                torch.save(model.state_dict(), save_pth)\n",
    "            elif len([v for v in validation_loss_history[-stopping_treshold:] if v > validation_loss_minimum]) >= stopping_treshold:\n",
    "                print(f\"Stopping early at epoch: {epoch}/{n_epochs}\")\n",
    "                break\n",
    "        \n",
    "\n",
    "    return train_loss_history, validation_loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training - 32x32 resolution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(32),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "                                      ])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(34),\n",
    "                                      transforms.CenterCrop(32),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "                                    ])\n",
    "# setting up data loaders\n",
    "data_dir = os.path.join(os.pardir, 'data', 'Plant_leave_diseases_32')\n",
    "\n",
    "train_data = datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(os.path.join(data_dir, 'validation'), transform=test_transforms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs \n",
    "config = {\n",
    "    'max_epochs': 200,\n",
    "    'learning_rate': 0.002,\n",
    "    'resolution': 32,\n",
    "    'name': 'resnet50_32'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ngrec\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\plant-leaf-diseases-identification-CBiGMIHu-py3.8\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/200, Training Loss: 2.512, Train accuracy 0.329 Validation Loss: 2.136, Validation accuracy 0.404\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 2/200, Training Loss: 2.297, Train accuracy 0.370 Validation Loss: 2.050, Validation accuracy 0.424\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 3/200, Training Loss: 2.237, Train accuracy 0.387 Validation Loss: 2.002, Validation accuracy 0.442\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 4/200, Training Loss: 2.201, Train accuracy 0.394 Validation Loss: 2.031, Validation accuracy 0.437\n",
      "Epoch: 5/200, Training Loss: 2.180, Train accuracy 0.400 Validation Loss: 1.971, Validation accuracy 0.440\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 6/200, Training Loss: 2.167, Train accuracy 0.404 Validation Loss: 1.941, Validation accuracy 0.458\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 7/200, Training Loss: 2.157, Train accuracy 0.406 Validation Loss: 1.919, Validation accuracy 0.462\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 8/200, Training Loss: 2.132, Train accuracy 0.411 Validation Loss: 1.918, Validation accuracy 0.458\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 9/200, Training Loss: 2.126, Train accuracy 0.413 Validation Loss: 1.906, Validation accuracy 0.455\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 10/200, Training Loss: 2.110, Train accuracy 0.418 Validation Loss: 1.905, Validation accuracy 0.465\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 11/200, Training Loss: 2.109, Train accuracy 0.418 Validation Loss: 1.876, Validation accuracy 0.467\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 12/200, Training Loss: 2.093, Train accuracy 0.422 Validation Loss: 1.914, Validation accuracy 0.455\n",
      "Epoch: 13/200, Training Loss: 2.088, Train accuracy 0.423 Validation Loss: 1.906, Validation accuracy 0.469\n",
      "Epoch: 14/200, Training Loss: 2.081, Train accuracy 0.425 Validation Loss: 1.923, Validation accuracy 0.457\n",
      "Epoch: 15/200, Training Loss: 2.080, Train accuracy 0.426 Validation Loss: 1.847, Validation accuracy 0.474\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 16/200, Training Loss: 2.075, Train accuracy 0.426 Validation Loss: 1.895, Validation accuracy 0.474\n",
      "Epoch: 17/200, Training Loss: 2.067, Train accuracy 0.431 Validation Loss: 1.861, Validation accuracy 0.469\n",
      "Epoch: 18/200, Training Loss: 2.068, Train accuracy 0.430 Validation Loss: 1.861, Validation accuracy 0.476\n",
      "Epoch: 19/200, Training Loss: 2.072, Train accuracy 0.430 Validation Loss: 1.854, Validation accuracy 0.478\n",
      "Epoch: 20/200, Training Loss: 2.060, Train accuracy 0.432 Validation Loss: 1.829, Validation accuracy 0.476\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 21/200, Training Loss: 2.064, Train accuracy 0.432 Validation Loss: 1.837, Validation accuracy 0.487\n",
      "Epoch: 22/200, Training Loss: 2.064, Train accuracy 0.431 Validation Loss: 1.813, Validation accuracy 0.485\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 23/200, Training Loss: 2.054, Train accuracy 0.431 Validation Loss: 1.798, Validation accuracy 0.485\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 24/200, Training Loss: 2.044, Train accuracy 0.432 Validation Loss: 1.863, Validation accuracy 0.474\n",
      "Epoch: 25/200, Training Loss: 2.050, Train accuracy 0.432 Validation Loss: 1.801, Validation accuracy 0.484\n",
      "Epoch: 26/200, Training Loss: 2.040, Train accuracy 0.438 Validation Loss: 1.827, Validation accuracy 0.477\n",
      "Epoch: 27/200, Training Loss: 2.034, Train accuracy 0.439 Validation Loss: 1.798, Validation accuracy 0.483\n",
      "Epoch: 28/200, Training Loss: 2.030, Train accuracy 0.438 Validation Loss: 1.831, Validation accuracy 0.478\n",
      "Epoch: 29/200, Training Loss: 2.036, Train accuracy 0.441 Validation Loss: 1.802, Validation accuracy 0.489\n",
      "Epoch: 30/200, Training Loss: 2.031, Train accuracy 0.440 Validation Loss: 1.825, Validation accuracy 0.474\n",
      "Epoch: 31/200, Training Loss: 2.034, Train accuracy 0.441 Validation Loss: 1.791, Validation accuracy 0.496\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 32/200, Training Loss: 2.032, Train accuracy 0.438 Validation Loss: 1.842, Validation accuracy 0.477\n",
      "Epoch: 33/200, Training Loss: 2.028, Train accuracy 0.439 Validation Loss: 1.821, Validation accuracy 0.483\n",
      "Epoch: 34/200, Training Loss: 2.033, Train accuracy 0.437 Validation Loss: 1.796, Validation accuracy 0.490\n",
      "Epoch: 35/200, Training Loss: 2.022, Train accuracy 0.442 Validation Loss: 1.839, Validation accuracy 0.483\n",
      "Epoch: 36/200, Training Loss: 2.026, Train accuracy 0.443 Validation Loss: 1.781, Validation accuracy 0.491\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 37/200, Training Loss: 2.031, Train accuracy 0.441 Validation Loss: 1.817, Validation accuracy 0.495\n",
      "Epoch: 38/200, Training Loss: 2.020, Train accuracy 0.443 Validation Loss: 1.768, Validation accuracy 0.499\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 39/200, Training Loss: 2.030, Train accuracy 0.442 Validation Loss: 1.797, Validation accuracy 0.497\n",
      "Epoch: 40/200, Training Loss: 2.019, Train accuracy 0.444 Validation Loss: 1.781, Validation accuracy 0.499\n",
      "Epoch: 41/200, Training Loss: 2.019, Train accuracy 0.441 Validation Loss: 1.755, Validation accuracy 0.508\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 42/200, Training Loss: 2.016, Train accuracy 0.443 Validation Loss: 1.764, Validation accuracy 0.503\n",
      "Epoch: 43/200, Training Loss: 2.016, Train accuracy 0.443 Validation Loss: 1.802, Validation accuracy 0.491\n",
      "Epoch: 44/200, Training Loss: 2.019, Train accuracy 0.443 Validation Loss: 1.796, Validation accuracy 0.496\n",
      "Epoch: 45/200, Training Loss: 2.020, Train accuracy 0.444 Validation Loss: 1.774, Validation accuracy 0.500\n",
      "Epoch: 46/200, Training Loss: 2.017, Train accuracy 0.442 Validation Loss: 1.785, Validation accuracy 0.500\n",
      "Epoch: 47/200, Training Loss: 2.013, Train accuracy 0.442 Validation Loss: 1.791, Validation accuracy 0.497\n",
      "Epoch: 48/200, Training Loss: 2.012, Train accuracy 0.447 Validation Loss: 1.777, Validation accuracy 0.495\n",
      "Epoch: 49/200, Training Loss: 2.008, Train accuracy 0.447 Validation Loss: 1.776, Validation accuracy 0.493\n",
      "Epoch: 50/200, Training Loss: 2.016, Train accuracy 0.447 Validation Loss: 1.780, Validation accuracy 0.495\n",
      "Epoch: 51/200, Training Loss: 2.018, Train accuracy 0.444 Validation Loss: 1.801, Validation accuracy 0.487\n",
      "Epoch: 52/200, Training Loss: 2.015, Train accuracy 0.447 Validation Loss: 1.737, Validation accuracy 0.500\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 53/200, Training Loss: 2.013, Train accuracy 0.446 Validation Loss: 1.747, Validation accuracy 0.501\n",
      "Epoch: 54/200, Training Loss: 2.016, Train accuracy 0.444 Validation Loss: 1.815, Validation accuracy 0.498\n",
      "Epoch: 55/200, Training Loss: 2.007, Train accuracy 0.447 Validation Loss: 1.801, Validation accuracy 0.495\n",
      "Epoch: 56/200, Training Loss: 2.015, Train accuracy 0.445 Validation Loss: 1.776, Validation accuracy 0.493\n",
      "Epoch: 57/200, Training Loss: 2.012, Train accuracy 0.445 Validation Loss: 1.761, Validation accuracy 0.504\n",
      "Epoch: 58/200, Training Loss: 2.009, Train accuracy 0.446 Validation Loss: 1.772, Validation accuracy 0.497\n",
      "Epoch: 59/200, Training Loss: 2.012, Train accuracy 0.444 Validation Loss: 1.773, Validation accuracy 0.503\n",
      "Epoch: 60/200, Training Loss: 2.007, Train accuracy 0.445 Validation Loss: 1.791, Validation accuracy 0.494\n",
      "Epoch: 61/200, Training Loss: 2.006, Train accuracy 0.446 Validation Loss: 1.791, Validation accuracy 0.499\n",
      "Epoch: 62/200, Training Loss: 2.010, Train accuracy 0.446 Validation Loss: 1.769, Validation accuracy 0.500\n",
      "Epoch: 63/200, Training Loss: 2.014, Train accuracy 0.445 Validation Loss: 1.787, Validation accuracy 0.494\n",
      "Epoch: 64/200, Training Loss: 2.013, Train accuracy 0.446 Validation Loss: 1.775, Validation accuracy 0.499\n",
      "Epoch: 65/200, Training Loss: 2.009, Train accuracy 0.446 Validation Loss: 1.771, Validation accuracy 0.499\n",
      "Epoch: 66/200, Training Loss: 2.004, Train accuracy 0.449 Validation Loss: 1.801, Validation accuracy 0.487\n",
      "Epoch: 67/200, Training Loss: 2.005, Train accuracy 0.449 Validation Loss: 1.779, Validation accuracy 0.503\n",
      "Stopping early at epoch: 67/200\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=True)\n",
    "\n",
    "mlflow.set_experiment(\"Plant Leaf Disease\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param('framework', 'pytorch')\n",
    "    mlflow.log_param('data_split', '90/10')\n",
    "    mlflow.log_param('type', 'Resnet50')\n",
    "    mlflow.log_params(config)\n",
    "    train(mdl, train_loader, validation_loader, config, n_epochs=config['max_epochs'], stopping_treshold=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training 224X224 resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "                                      ])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "                                    ])\n",
    "\n",
    "# setting up data loaders\n",
    "data_dir = os.path.join(os.pardir, 'data', 'Plant_leave_diseases_224')\n",
    "\n",
    "train_data = datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(os.path.join(data_dir, 'validation'), transform=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = models.resnet50(pretrained=True)\n",
    "\n",
    "# Freezing the paramiters of the layers we do not want to train\n",
    "for parameters in mdl.parameters():\n",
    "    parameters.requires_grad = False\n",
    "\n",
    "# Updating Classification layer \n",
    "_inputs = mdl.fc.in_features\n",
    "\n",
    "mdl.fc = nn.Sequential(OrderedDict([\n",
    "    ('fc1', nn.Linear(_inputs, 500)),\n",
    "    ('relu', nn.ReLU()),\n",
    "    ('dropout', nn.Dropout(0.2)),\n",
    "    ('fc2', nn.Linear(500, 39)),\n",
    "    ('output', nn.LogSoftmax(dim=1))\n",
    "]))\n",
    "\n",
    "# Configs \n",
    "config = {\n",
    "    'max_epochs': 200,\n",
    "    'learning_rate': 0.002,\n",
    "    'resolution': 224,\n",
    "    'name': 'resnet50_224'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n",
      "Epoch: 1/200, Training Loss: 1.034, Train accuracy 0.698 Validation Loss: 0.460, Validation accuracy 0.853\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 2/200, Training Loss: 0.701, Train accuracy 0.782 Validation Loss: 0.376, Validation accuracy 0.875\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 3/200, Training Loss: 0.653, Train accuracy 0.796 Validation Loss: 0.330, Validation accuracy 0.892\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 4/200, Training Loss: 0.630, Train accuracy 0.806 Validation Loss: 0.343, Validation accuracy 0.882\n",
      "Epoch: 5/200, Training Loss: 0.609, Train accuracy 0.811 Validation Loss: 0.311, Validation accuracy 0.898\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 6/200, Training Loss: 0.586, Train accuracy 0.819 Validation Loss: 0.328, Validation accuracy 0.893\n",
      "Epoch: 7/200, Training Loss: 0.579, Train accuracy 0.821 Validation Loss: 0.334, Validation accuracy 0.890\n",
      "Epoch: 8/200, Training Loss: 0.568, Train accuracy 0.825 Validation Loss: 0.325, Validation accuracy 0.896\n",
      "Epoch: 9/200, Training Loss: 0.552, Train accuracy 0.829 Validation Loss: 0.287, Validation accuracy 0.910\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 10/200, Training Loss: 0.556, Train accuracy 0.829 Validation Loss: 0.299, Validation accuracy 0.901\n",
      "Epoch: 11/200, Training Loss: 0.538, Train accuracy 0.833 Validation Loss: 0.290, Validation accuracy 0.908\n",
      "Epoch: 12/200, Training Loss: 0.538, Train accuracy 0.835 Validation Loss: 0.262, Validation accuracy 0.911\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 13/200, Training Loss: 0.511, Train accuracy 0.841 Validation Loss: 0.283, Validation accuracy 0.902\n",
      "Epoch: 14/200, Training Loss: 0.523, Train accuracy 0.839 Validation Loss: 0.264, Validation accuracy 0.914\n",
      "Epoch: 15/200, Training Loss: 0.518, Train accuracy 0.838 Validation Loss: 0.268, Validation accuracy 0.910\n",
      "Epoch: 16/200, Training Loss: 0.508, Train accuracy 0.845 Validation Loss: 0.265, Validation accuracy 0.913\n",
      "Epoch: 17/200, Training Loss: 0.502, Train accuracy 0.845 Validation Loss: 0.243, Validation accuracy 0.918\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 18/200, Training Loss: 0.491, Train accuracy 0.848 Validation Loss: 0.251, Validation accuracy 0.917\n",
      "Epoch: 19/200, Training Loss: 0.501, Train accuracy 0.846 Validation Loss: 0.233, Validation accuracy 0.919\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 20/200, Training Loss: 0.485, Train accuracy 0.850 Validation Loss: 0.257, Validation accuracy 0.920\n",
      "Epoch: 21/200, Training Loss: 0.488, Train accuracy 0.851 Validation Loss: 0.294, Validation accuracy 0.901\n",
      "Epoch: 22/200, Training Loss: 0.489, Train accuracy 0.849 Validation Loss: 0.233, Validation accuracy 0.925\n",
      "Epoch: 23/200, Training Loss: 0.483, Train accuracy 0.852 Validation Loss: 0.243, Validation accuracy 0.920\n",
      "Epoch: 24/200, Training Loss: 0.484, Train accuracy 0.852 Validation Loss: 0.240, Validation accuracy 0.922\n",
      "Epoch: 25/200, Training Loss: 0.477, Train accuracy 0.854 Validation Loss: 0.252, Validation accuracy 0.914\n",
      "Epoch: 26/200, Training Loss: 0.469, Train accuracy 0.856 Validation Loss: 0.230, Validation accuracy 0.925\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 27/200, Training Loss: 0.459, Train accuracy 0.860 Validation Loss: 0.249, Validation accuracy 0.916\n",
      "Epoch: 28/200, Training Loss: 0.458, Train accuracy 0.859 Validation Loss: 0.244, Validation accuracy 0.919\n",
      "Epoch: 29/200, Training Loss: 0.459, Train accuracy 0.859 Validation Loss: 0.231, Validation accuracy 0.925\n",
      "Epoch: 30/200, Training Loss: 0.464, Train accuracy 0.858 Validation Loss: 0.222, Validation accuracy 0.927\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 31/200, Training Loss: 0.461, Train accuracy 0.858 Validation Loss: 0.221, Validation accuracy 0.928\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 32/200, Training Loss: 0.459, Train accuracy 0.860 Validation Loss: 0.233, Validation accuracy 0.927\n",
      "Epoch: 33/200, Training Loss: 0.448, Train accuracy 0.861 Validation Loss: 0.237, Validation accuracy 0.922\n",
      "Epoch: 34/200, Training Loss: 0.453, Train accuracy 0.862 Validation Loss: 0.236, Validation accuracy 0.919\n",
      "Epoch: 35/200, Training Loss: 0.453, Train accuracy 0.861 Validation Loss: 0.213, Validation accuracy 0.931\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 36/200, Training Loss: 0.449, Train accuracy 0.862 Validation Loss: 0.217, Validation accuracy 0.932\n",
      "Epoch: 37/200, Training Loss: 0.434, Train accuracy 0.866 Validation Loss: 0.223, Validation accuracy 0.926\n",
      "Epoch: 38/200, Training Loss: 0.440, Train accuracy 0.865 Validation Loss: 0.219, Validation accuracy 0.929\n",
      "Epoch: 39/200, Training Loss: 0.436, Train accuracy 0.868 Validation Loss: 0.211, Validation accuracy 0.931\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 40/200, Training Loss: 0.431, Train accuracy 0.869 Validation Loss: 0.222, Validation accuracy 0.933\n",
      "Epoch: 41/200, Training Loss: 0.439, Train accuracy 0.866 Validation Loss: 0.228, Validation accuracy 0.926\n",
      "Epoch: 42/200, Training Loss: 0.441, Train accuracy 0.864 Validation Loss: 0.203, Validation accuracy 0.936\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 43/200, Training Loss: 0.427, Train accuracy 0.869 Validation Loss: 0.199, Validation accuracy 0.937\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 44/200, Training Loss: 0.438, Train accuracy 0.867 Validation Loss: 0.210, Validation accuracy 0.928\n",
      "Epoch: 45/200, Training Loss: 0.427, Train accuracy 0.869 Validation Loss: 0.211, Validation accuracy 0.928\n",
      "Epoch: 46/200, Training Loss: 0.429, Train accuracy 0.868 Validation Loss: 0.221, Validation accuracy 0.929\n",
      "Epoch: 47/200, Training Loss: 0.427, Train accuracy 0.869 Validation Loss: 0.197, Validation accuracy 0.934\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 48/200, Training Loss: 0.431, Train accuracy 0.869 Validation Loss: 0.214, Validation accuracy 0.930\n",
      "Epoch: 49/200, Training Loss: 0.424, Train accuracy 0.870 Validation Loss: 0.192, Validation accuracy 0.939\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 50/200, Training Loss: 0.428, Train accuracy 0.869 Validation Loss: 0.228, Validation accuracy 0.926\n",
      "Epoch: 51/200, Training Loss: 0.422, Train accuracy 0.870 Validation Loss: 0.219, Validation accuracy 0.932\n",
      "Epoch: 52/200, Training Loss: 0.419, Train accuracy 0.872 Validation Loss: 0.229, Validation accuracy 0.928\n",
      "Epoch: 53/200, Training Loss: 0.419, Train accuracy 0.871 Validation Loss: 0.240, Validation accuracy 0.923\n",
      "Epoch: 54/200, Training Loss: 0.413, Train accuracy 0.873 Validation Loss: 0.215, Validation accuracy 0.932\n",
      "Epoch: 55/200, Training Loss: 0.416, Train accuracy 0.874 Validation Loss: 0.206, Validation accuracy 0.935\n",
      "Epoch: 56/200, Training Loss: 0.418, Train accuracy 0.871 Validation Loss: 0.197, Validation accuracy 0.936\n",
      "Epoch: 57/200, Training Loss: 0.421, Train accuracy 0.872 Validation Loss: 0.197, Validation accuracy 0.935\n",
      "Epoch: 58/200, Training Loss: 0.422, Train accuracy 0.870 Validation Loss: 0.219, Validation accuracy 0.929\n",
      "Epoch: 59/200, Training Loss: 0.419, Train accuracy 0.871 Validation Loss: 0.188, Validation accuracy 0.935\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 60/200, Training Loss: 0.413, Train accuracy 0.874 Validation Loss: 0.183, Validation accuracy 0.935\n",
      "New minimum validation loss (saving model)\n",
      "Epoch: 61/200, Training Loss: 0.408, Train accuracy 0.876 Validation Loss: 0.202, Validation accuracy 0.935\n",
      "Epoch: 62/200, Training Loss: 0.411, Train accuracy 0.874 Validation Loss: 0.198, Validation accuracy 0.930\n",
      "Epoch: 63/200, Training Loss: 0.415, Train accuracy 0.873 Validation Loss: 0.207, Validation accuracy 0.928\n",
      "Epoch: 64/200, Training Loss: 0.411, Train accuracy 0.874 Validation Loss: 0.204, Validation accuracy 0.934\n",
      "Epoch: 65/200, Training Loss: 0.418, Train accuracy 0.874 Validation Loss: 0.212, Validation accuracy 0.932\n",
      "Epoch: 66/200, Training Loss: 0.403, Train accuracy 0.877 Validation Loss: 0.210, Validation accuracy 0.934\n",
      "Epoch: 67/200, Training Loss: 0.403, Train accuracy 0.876 Validation Loss: 0.204, Validation accuracy 0.931\n",
      "Epoch: 68/200, Training Loss: 0.402, Train accuracy 0.877 Validation Loss: 0.193, Validation accuracy 0.937\n",
      "Epoch: 69/200, Training Loss: 0.403, Train accuracy 0.877 Validation Loss: 0.197, Validation accuracy 0.936\n",
      "Epoch: 70/200, Training Loss: 0.398, Train accuracy 0.879 Validation Loss: 0.212, Validation accuracy 0.932\n",
      "Epoch: 71/200, Training Loss: 0.402, Train accuracy 0.879 Validation Loss: 0.210, Validation accuracy 0.936\n",
      "Epoch: 72/200, Training Loss: 0.402, Train accuracy 0.879 Validation Loss: 0.195, Validation accuracy 0.940\n",
      "Epoch: 73/200, Training Loss: 0.400, Train accuracy 0.878 Validation Loss: 0.196, Validation accuracy 0.939\n",
      "Epoch: 74/200, Training Loss: 0.398, Train accuracy 0.879 Validation Loss: 0.192, Validation accuracy 0.940\n",
      "Epoch: 75/200, Training Loss: 0.398, Train accuracy 0.878 Validation Loss: 0.210, Validation accuracy 0.937\n",
      "Stopping early at epoch: 75/200\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=True)\n",
    "\n",
    "mlflow.set_experiment(\"Plant Leaf Disease\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param('framework', 'pytorch')\n",
    "    mlflow.log_param('data_split', '90/10')\n",
    "    mlflow.log_param('type', 'Resnet50')\n",
    "    mlflow.log_params(config)\n",
    "    train(mdl, train_loader, validation_loader, config, n_epochs=config['max_epochs'], stopping_treshold=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d53c06ab4573055b295bcdfb3b25bc2da21e5ae576a05184a9c53fc2168185ab"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('plant-leaf-diseases-identification-CBiGMIHu-py3.8': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
