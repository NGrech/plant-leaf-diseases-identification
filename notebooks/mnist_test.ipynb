{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mnist Fashion Test"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 102,
>>>>>>> origin
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import urllib.request\n",
    "import cv2\n",
    "import mlflow\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from zipfile import ZipFile\n",
    "import sys\n",
    "sys.path.insert(1, r'../src')\n",
    "\n",
    "\n",
    "import model\n",
    "\n",
    "from utils import one_hot_encode_index\n",
    "\n",
    "from optimizers import Adam\n",
    "from activations import Softmax, ReLU\n",
    "from layers import Dropout, LinearLayer\n",
    "from loss import CategoricalCrossEntropyLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 103,
>>>>>>> origin
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://nnfs.io/datasets/fashion_mnist_images.zip'\n",
    "FILE = 'fashion_mnist_images.zip'\n",
    "FOLDER = 'fashion_mnist_images'\n",
    "\n",
    "if not os.path.isfile(FILE):\n",
    "    print(f'Downloading {URL} and saving as {FILE}...')\n",
    "    urllib.request.urlretrieve(URL, FILE)\n",
    "\n",
    "print('Unzipping images...')\n",
    "with ZipFile(FILE) as zip_images:\n",
    "    zip_images.extractall(FOLDER)\n",
    "\n",
    "print('Done!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 104,
>>>>>>> origin
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads a MNIST dataset\n",
    "def load_mnist_dataset(dataset, path):\n",
    "    # Scan all the directories and create a list of labels\n",
    "    labels = os.listdir(os.path.join(path, dataset))\n",
    "    # Create lists for samples and labels\n",
    "    X = []\n",
    "    y = []\n",
    "    # For each label folder\n",
    "    for label in labels:\n",
    "        # And for each image in given folder\n",
    "        for file in os.listdir(os.path.join(path, dataset, label)):\n",
    "            # Read the image\n",
    "            image = cv2.imread(os.path.join(path, dataset, label, file), cv2.IMREAD_UNCHANGED)\n",
    "            # And append it and a label to the lists\n",
    "            X.append(image)\n",
    "            y.append(label)\n",
    "    # Convert the data to proper numpy arrays and return\n",
    "    return np.array(X), np.array(y).astype('uint8')\n",
    "\n",
    "\n",
    "def create_data_mnist(path):\n",
    "    # Load both sets separately\n",
    "    X, y = load_mnist_dataset('train', path)\n",
    "    X_test, y_test = load_mnist_dataset('test', path)\n",
    "    y = one_hot_encode_index(y, 10)\n",
    "    y_test = one_hot_encode_index(y_test, 10)\n",
    "    \n",
    "    # And return all the data\n",
    "    return X, y, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 105,
>>>>>>> origin
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, X_test, y_test = create_data_mnist('fashion_mnist_images')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling between -1 & 1"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 106,
>>>>>>> origin
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_img(v):\n",
    "    return (v - 127.5) /127.5\n",
    "\n",
    "X = scale_img(X)\n",
    "X_test = scale_img(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping data "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 107,
>>>>>>> origin
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(v):\n",
    "    return v.reshape(v.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 108,
>>>>>>> origin
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorize(X)\n",
    "X_test = vectorize(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle Training data "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 109,
>>>>>>> origin
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = np.array(range(X.shape[0]))\n",
    "np.random.shuffle(keys)\n",
    "X = X[keys]\n",
    "y = y[keys]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup MLfow "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 110,
>>>>>>> origin
   "metadata": {},
   "outputs": [],
   "source": [
    "## TESTING \n",
    "import importlib\n",
    "importlib.reload(model)\n",
    "##\n",
    "\n",
    "cce_loss = CategoricalCrossEntropyLoss()\n",
    "optimizer = Adam(decay=5e-5)\n",
    "\n",
    "my_model = model.Model(optimizer, cce_loss)\n",
    "my_model.set_save_config(model_name='tst_mdl', save_path=r'.\\models')\n",
    "\n",
    "my_model.set_sequence([\n",
    "                LinearLayer(X.shape[1], 128),\n",
    "                ReLU(),\n",
    "                Dropout(0.5),\n",
    "                LinearLayer(128, 128),\n",
    "                ReLU(),\n",
    "                LinearLayer(128, 10),\n",
    "                Softmax()\n",
    "            ])\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch: 1 ===\n",
      "Step: 0/469, accuracy0.094, loss3.743, learning rate 0.0010000 \n",
      "Step: 100/469, accuracy0.734, loss0.758, learning rate 0.0009950 \n",
      "Step: 200/469, accuracy0.805, loss0.567, learning rate 0.0009901 \n",
      "Step: 300/469, accuracy0.766, loss0.591, learning rate 0.0009852 \n",
      "Step: 400/469, accuracy0.766, loss0.624, learning rate 0.0009804 \n",
      "Step: 468/469, accuracy0.823, loss0.579, learning rate 0.0009771 \n",
      "Epoch: 1/10, accuracy0.750, loss0.702, learning rate 0.001\n",
      "--Validation--\n",
      "Validation : Accuracy: 0.829, Loss: 0.471\n",
      "=== Epoch: 2 ===\n",
      "Step: 0/469, accuracy0.859, loss0.444, learning rate 0.0009771 \n",
      "Step: 100/469, accuracy0.828, loss0.503, learning rate 0.0009723 \n",
      "Step: 200/469, accuracy0.836, loss0.470, learning rate 0.0009676 \n",
      "Step: 300/469, accuracy0.828, loss0.382, learning rate 0.0009630 \n",
      "Step: 400/469, accuracy0.805, loss0.597, learning rate 0.0009584 \n",
      "Step: 468/469, accuracy0.760, loss0.559, learning rate 0.0009552 \n",
      "Epoch: 2/10, accuracy0.812, loss0.521, learning rate 0.001\n",
      "--Validation--\n",
      "New best model ... saving\n",
      "Validation : Accuracy: 0.843, Loss: 0.429\n",
      "=== Epoch: 3 ===\n",
      "Step: 0/469, accuracy0.852, loss0.409, learning rate 0.0009552 \n",
      "Step: 100/469, accuracy0.797, loss0.477, learning rate 0.0009507 \n",
      "Step: 200/469, accuracy0.898, loss0.396, learning rate 0.0009462 \n",
      "Step: 300/469, accuracy0.836, loss0.413, learning rate 0.0009417 \n",
      "Step: 400/469, accuracy0.820, loss0.435, learning rate 0.0009373 \n",
      "Step: 468/469, accuracy0.802, loss0.533, learning rate 0.0009343 \n",
      "Epoch: 3/10, accuracy0.827, loss0.476, learning rate 0.001\n",
      "--Validation--\n",
      "New best model ... saving\n",
      "Validation : Accuracy: 0.845, Loss: 0.415\n",
      "=== Epoch: 4 ===\n",
      "Step: 0/469, accuracy0.891, loss0.362, learning rate 0.0009343 \n",
      "Step: 100/469, accuracy0.797, loss0.389, learning rate 0.0009299 \n",
      "Step: 200/469, accuracy0.875, loss0.372, learning rate 0.0009256 \n",
      "Step: 300/469, accuracy0.859, loss0.378, learning rate 0.0009214 \n",
      "Step: 400/469, accuracy0.805, loss0.585, learning rate 0.0009171 \n",
      "Step: 468/469, accuracy0.812, loss0.469, learning rate 0.0009143 \n",
      "Epoch: 4/10, accuracy0.835, loss0.454, learning rate 0.001\n",
      "--Validation--\n",
      "New best model ... saving\n",
      "Validation : Accuracy: 0.855, Loss: 0.400\n",
      "=== Epoch: 5 ===\n",
      "Step: 0/469, accuracy0.883, loss0.290, learning rate 0.0009142 \n",
      "Step: 100/469, accuracy0.828, loss0.415, learning rate 0.0009101 \n",
      "Step: 200/469, accuracy0.875, loss0.417, learning rate 0.0009060 \n",
      "Step: 300/469, accuracy0.828, loss0.413, learning rate 0.0009019 \n",
      "Step: 400/469, accuracy0.836, loss0.477, learning rate 0.0008978 \n",
      "Step: 468/469, accuracy0.823, loss0.486, learning rate 0.0008951 \n",
      "Epoch: 5/10, accuracy0.840, loss0.436, learning rate 0.001\n",
      "--Validation--\n",
      "New best model ... saving\n",
      "Validation : Accuracy: 0.856, Loss: 0.393\n",
      "=== Epoch: 6 ===\n",
      "Step: 0/469, accuracy0.891, loss0.267, learning rate 0.0008951 \n",
      "Step: 100/469, accuracy0.844, loss0.409, learning rate 0.0008911 \n",
      "Step: 200/469, accuracy0.922, loss0.356, learning rate 0.0008871 \n",
      "Step: 300/469, accuracy0.844, loss0.380, learning rate 0.0008832 \n",
      "Step: 400/469, accuracy0.836, loss0.468, learning rate 0.0008793 \n",
      "Step: 468/469, accuracy0.875, loss0.405, learning rate 0.0008767 \n",
      "Epoch: 6/10, accuracy0.847, loss0.419, learning rate 0.001\n",
      "--Validation--\n",
      "New best model ... saving\n",
      "Validation : Accuracy: 0.861, Loss: 0.383\n",
      "=== Epoch: 7 ===\n",
      "Step: 0/469, accuracy0.883, loss0.319, learning rate 0.0008767 \n",
      "Step: 100/469, accuracy0.828, loss0.412, learning rate 0.0008728 \n",
      "Step: 200/469, accuracy0.875, loss0.340, learning rate 0.0008690 \n",
      "Step: 300/469, accuracy0.852, loss0.380, learning rate 0.0008653 \n",
      "Step: 400/469, accuracy0.875, loss0.389, learning rate 0.0008615 \n",
      "Step: 468/469, accuracy0.885, loss0.428, learning rate 0.0008590 \n",
      "Epoch: 7/10, accuracy0.852, loss0.406, learning rate 0.001\n",
      "--Validation--\n",
      "New best model ... saving\n",
      "Validation : Accuracy: 0.863, Loss: 0.381\n",
      "=== Epoch: 8 ===\n",
      "Step: 0/469, accuracy0.898, loss0.260, learning rate 0.0008590 \n",
      "Step: 100/469, accuracy0.859, loss0.382, learning rate 0.0008553 \n",
      "Step: 200/469, accuracy0.891, loss0.308, learning rate 0.0008517 \n",
      "Step: 300/469, accuracy0.867, loss0.348, learning rate 0.0008481 \n",
      "Step: 400/469, accuracy0.844, loss0.439, learning rate 0.0008445 \n",
      "Step: 468/469, accuracy0.823, loss0.381, learning rate 0.0008421 \n",
      "Epoch: 8/10, accuracy0.855, loss0.399, learning rate 0.001\n",
      "--Validation--\n",
      "New best model ... saving\n",
      "Validation : Accuracy: 0.867, Loss: 0.375\n",
      "=== Epoch: 9 ===\n",
      "Step: 0/469, accuracy0.914, loss0.284, learning rate 0.0008420 \n",
      "Step: 100/469, accuracy0.844, loss0.324, learning rate 0.0008385 \n",
      "Step: 200/469, accuracy0.883, loss0.348, learning rate 0.0008350 \n",
      "Step: 300/469, accuracy0.859, loss0.347, learning rate 0.0008315 \n",
      "Step: 400/469, accuracy0.844, loss0.472, learning rate 0.0008281 \n",
      "Step: 468/469, accuracy0.812, loss0.413, learning rate 0.0008258 \n",
      "Epoch: 9/10, accuracy0.858, loss0.389, learning rate 0.001\n",
      "--Validation--\n",
      "New best model ... saving\n",
      "Validation : Accuracy: 0.865, Loss: 0.370\n",
      "=== Epoch: 10 ===\n",
      "Step: 0/469, accuracy0.922, loss0.255, learning rate 0.0008257 \n",
      "Step: 100/469, accuracy0.867, loss0.351, learning rate 0.0008223 \n",
      "Step: 200/469, accuracy0.906, loss0.316, learning rate 0.0008190 \n",
      "Step: 300/469, accuracy0.828, loss0.416, learning rate 0.0008156 \n",
      "Step: 400/469, accuracy0.820, loss0.506, learning rate 0.0008123 \n",
      "Step: 468/469, accuracy0.854, loss0.365, learning rate 0.0008101 \n",
      "Epoch: 10/10, accuracy0.859, loss0.383, learning rate 0.001\n",
      "--Validation--\n",
      "Validation : Accuracy: 0.865, Loss: 0.373\n"
     ]
    }
   ],
>>>>>>> origin
   "source": [
    "mlflow.set_experiment(experiment_name='MNIST Fashion')\n",
    "\n",
    "tags = {'Network_Type':'FFNN'}\n",
    "\n",
    "with mlflow.start_run():\n",
    "    my_model.train(X, y, epochs=10, batch_size=128, validation=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation : Accuracy: 0.865, Loss: 0.373\n"
     ]
    }
   ],
>>>>>>> origin
   "source": [
    "my_model.evaluate(X_test, y_test, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5734eafda3611ac4cda01bcae68efeb7a0fca20a99bcb218ad2b0b92f206bf5c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('plantLeafDiseases': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
