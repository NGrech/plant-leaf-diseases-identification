{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import urllib.request\n",
    "import cv2\n",
    "import mlflow\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import mlflow\n",
    "\n",
    "from zipfile import ZipFile\n",
    "import sys\n",
    "# sys.path.append(r'../src')\n",
    "import importlib\n",
    "\n",
    "import model\n",
    "import layers\n",
    "import activations\n",
    "\n",
    "from utils import one_hot_encode_index\n",
    "from optimizers import Adam\n",
    "from activations import Softmax, ReLU\n",
    "from layers import Dropout, LinearLayer, ConvolutionLayer, PoolingLayer, FlattenLayer\n",
    "from loss import CategoricalCrossEntropyLoss\n",
    "\n",
    "def nsgpmnet_reloads():\n",
    "\n",
    "    importlib.reload(model)\n",
    "    importlib.reload(layers)\n",
    "    importlib.reload(activations)\n",
    "\n",
    "nsgpmnet_reloads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading MNIST-fashion-data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads a MNIST dataset\n",
    "def load_mnist_dataset(dataset, path):\n",
    "    # Scan all the directories and create a list of labels\n",
    "    labels = os.listdir(os.path.join(path, dataset))\n",
    "    # Create lists for samples and labels\n",
    "    X = []\n",
    "    y = []\n",
    "    # For each label folder\n",
    "    for label in labels:\n",
    "        # And for each image in given folder\n",
    "        for file in os.listdir(os.path.join(path, dataset, label)):\n",
    "            # Read the image\n",
    "            image = cv2.imread(os.path.join(path, dataset, label, file), cv2.IMREAD_UNCHANGED)\n",
    "            # And append it and a label to the lists\n",
    "            X.append(image)\n",
    "            y.append(label)\n",
    "    # Convert the data to proper numpy arrays and return\n",
    "    return np.array(X), np.array(y).astype('uint8')\n",
    "\n",
    "\n",
    "def create_data_mnist(path):\n",
    "    # Load both sets separately\n",
    "    X, y = load_mnist_dataset('train', path)\n",
    "    X_test, y_test = load_mnist_dataset('test', path)\n",
    "    y = one_hot_encode_index(y, 10)\n",
    "    y_test = one_hot_encode_index(y_test, 10)\n",
    "    \n",
    "    # And return all the data\n",
    "    return X, y, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "path0 = '/Users/petermagnusson/Documents/data/courses to study/malmoÌˆ universitet/3 ht2021/120p 2yrs MSc copmuter science - applied data science/course AI for data science/project/leaf/data/fashion_mnist_images'\n",
    "\n",
    "X, y, X_test, y_test = create_data_mnist(path0)\n",
    "\n",
    "y_flat = y.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handy print fuction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_info(a):\n",
    "    print('shapes for inputs and outputs:')\n",
    "    print(a.shape)\n",
    "    print('(min, max) for inputs and outputs:')\n",
    "    print(np.min(a), np.max(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle Training data - on initial loaded data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = np.array(range(X.shape[0]))\n",
    "np.random.shuffle(keys)\n",
    "X = X[keys]\n",
    "y = y[keys]\n",
    "y_flat = y_flat[keys]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping data for cnn-model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_channles(v):\n",
    "    return np.expand_dims(v, axis=1)\n",
    "\n",
    "X_chns = add_channles(X)\n",
    "X_chns_test = add_channles(X_test)\n",
    "\n",
    "# Optional truncation to fewer images for integration and timing testing.\n",
    "tval = 59904 # 200, 59968 (for batch_size=64), 59904 (for batch_size=128) 9984, 1024, 2048\n",
    "X_chns = X_chns[:tval, :, :]\n",
    "X_chns_test = X_chns_test[:tval, :, :]\n",
    "\n",
    "# print_info(X)\n",
    "# print_info(X_chns)\n",
    "# print_info(X_chns_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling between -1 and 1 - cnn-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_img(v):\n",
    "    return (v - 127.5) /127.5\n",
    "\n",
    "X_chns = scale_img(X_chns)\n",
    "X_chns_test = scale_img(X_chns_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle Training data - cnn-model - after truncation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = np.array(range(X_chns.shape[0]))\n",
    "np.random.shuffle(keys)\n",
    "X_chns = X_chns[keys]\n",
    "y = y[keys]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a reduced cnn-model sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cce_loss = CategoricalCrossEntropyLoss()\n",
    "optimizer = Adam(decay=5e-5)\n",
    "my_model = model.Model(optimizer, cce_loss)\n",
    "\n",
    "my_model.set_sequence([\n",
    "                ConvolutionLayer(1, 1, 3),\n",
    "                FlattenLayer(),\n",
    "                LinearLayer(676, 128),\n",
    "                ReLU(),\n",
    "                Dropout(0.5),\n",
    "                LinearLayer(128, 128),\n",
    "                ReLU(),\n",
    "                LinearLayer(128, 10),\n",
    "                Softmax()\n",
    "            ])\n",
    "\n",
    "# Setting the model save path:\n",
    "path1 = '/Users/petermagnusson/VisualStudioCodeProjects/saved_models/model1'\n",
    "my_model.set_save_config(model_name='cnn_9_0', save_path=path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_info(X)\n",
    "print_info(X_chns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with the reduced cnn-model, optional monitoring with MLflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch: 1 ===\n",
      "Step: 0/468, accuracy0.109, loss2.385, learning rate 0.0010000 \n",
      "Step: 100/468, accuracy0.688, loss0.850, learning rate 0.0009950 \n",
      "Step: 200/468, accuracy0.648, loss0.929, learning rate 0.0009901 \n",
      "Step: 300/468, accuracy0.781, loss0.817, learning rate 0.0009852 \n",
      "Step: 400/468, accuracy0.781, loss0.635, learning rate 0.0009804 \n",
      "Step: 467/468, accuracy0.781, loss0.650, learning rate 0.0009772 \n",
      "Epoch: 1/10, accuracy0.668, loss1.041, learning rate 0.001\n",
      "--Validation--\n",
      "Validation : Accuracy: 0.818, Loss: 0.508\n",
      "=== Epoch: 2 ===\n",
      "Step: 0/468, accuracy0.812, loss0.639, learning rate 0.0009771 \n",
      "Step: 100/468, accuracy0.805, loss0.534, learning rate 0.0009724 \n",
      "Step: 200/468, accuracy0.797, loss0.635, learning rate 0.0009677 \n",
      "Step: 300/468, accuracy0.703, loss0.875, learning rate 0.0009630 \n",
      "Step: 400/468, accuracy0.805, loss0.586, learning rate 0.0009584 \n",
      "Step: 467/468, accuracy0.797, loss0.602, learning rate 0.0009553 \n",
      "Epoch: 2/10, accuracy0.793, loss0.591, learning rate 0.001\n",
      "--Validation--\n",
      "Validation : Accuracy: 0.828, Loss: 0.510\n",
      "=== Epoch: 3 ===\n",
      "Step: 0/468, accuracy0.773, loss0.616, learning rate 0.0009553 \n",
      "Step: 100/468, accuracy0.695, loss0.824, learning rate 0.0009508 \n",
      "Step: 200/468, accuracy0.805, loss0.564, learning rate 0.0009463 \n",
      "Step: 300/468, accuracy0.773, loss0.726, learning rate 0.0009418 \n",
      "Step: 400/468, accuracy0.820, loss0.509, learning rate 0.0009374 \n",
      "Step: 467/468, accuracy0.797, loss0.557, learning rate 0.0009344 \n",
      "Epoch: 3/10, accuracy0.791, loss0.641, learning rate 0.001\n",
      "--Validation--\n",
      "New best model ... saving\n",
      "Validation : Accuracy: 0.842, Loss: 0.438\n",
      "=== Epoch: 4 ===\n",
      "Step: 0/468, accuracy0.789, loss0.554, learning rate 0.0009344 \n",
      "Step: 100/468, accuracy0.805, loss0.563, learning rate 0.0009301 \n",
      "Step: 200/468, accuracy0.797, loss0.558, learning rate 0.0009258 \n",
      "Step: 300/468, accuracy0.789, loss0.689, learning rate 0.0009215 \n",
      "Step: 400/468, accuracy0.828, loss0.407, learning rate 0.0009173 \n",
      "Step: 467/468, accuracy0.836, loss0.465, learning rate 0.0009145 \n",
      "Epoch: 4/10, accuracy0.826, loss0.491, learning rate 0.001\n",
      "--Validation--\n",
      "New best model ... saving\n",
      "Validation : Accuracy: 0.851, Loss: 0.409\n",
      "=== Epoch: 5 ===\n",
      "Step: 0/468, accuracy0.805, loss0.521, learning rate 0.0009144 \n",
      "Step: 100/468, accuracy0.789, loss0.512, learning rate 0.0009102 \n",
      "Step: 200/468, accuracy0.805, loss0.460, learning rate 0.0009061 \n",
      "Step: 300/468, accuracy0.781, loss0.608, learning rate 0.0009020 \n",
      "Step: 400/468, accuracy0.875, loss0.366, learning rate 0.0008980 \n",
      "Step: 467/468, accuracy0.602, loss2.229, learning rate 0.0008953 \n",
      "Epoch: 5/10, accuracy0.833, loss0.483, learning rate 0.001\n",
      "--Validation--\n",
      "Validation : Accuracy: 0.706, Loss: 1.018\n",
      "=== Epoch: 6 ===\n",
      "Step: 0/468, accuracy0.617, loss1.368, learning rate 0.0008953 \n",
      "Step: 100/468, accuracy0.789, loss0.552, learning rate 0.0008913 \n",
      "Step: 200/468, accuracy0.859, loss0.495, learning rate 0.0008873 \n",
      "Step: 300/468, accuracy0.797, loss0.614, learning rate 0.0008834 \n",
      "Step: 400/468, accuracy0.867, loss0.427, learning rate 0.0008795 \n",
      "Step: 467/468, accuracy0.852, loss0.496, learning rate 0.0008769 \n",
      "Epoch: 6/10, accuracy0.827, loss0.492, learning rate 0.001\n",
      "--Validation--\n",
      "New best model ... saving\n",
      "Validation : Accuracy: 0.854, Loss: 0.402\n",
      "=== Epoch: 7 ===\n",
      "Step: 0/468, accuracy0.844, loss0.465, learning rate 0.0008769 \n",
      "Step: 100/468, accuracy0.812, loss0.486, learning rate 0.0008731 \n",
      "Step: 200/468, accuracy0.828, loss0.442, learning rate 0.0008693 \n",
      "Step: 300/468, accuracy0.797, loss0.599, learning rate 0.0008655 \n",
      "Step: 400/468, accuracy0.859, loss0.409, learning rate 0.0008618 \n",
      "Step: 467/468, accuracy0.836, loss0.397, learning rate 0.0008593 \n",
      "Epoch: 7/10, accuracy0.848, loss0.420, learning rate 0.001\n",
      "--Validation--\n",
      "New best model ... saving\n",
      "Validation : Accuracy: 0.860, Loss: 0.393\n",
      "=== Epoch: 8 ===\n",
      "Step: 0/468, accuracy0.852, loss0.431, learning rate 0.0008593 \n",
      "Step: 100/468, accuracy0.836, loss0.458, learning rate 0.0008556 \n",
      "Step: 200/468, accuracy0.820, loss0.413, learning rate 0.0008519 \n",
      "Step: 300/468, accuracy0.812, loss0.578, learning rate 0.0008483 \n",
      "Step: 400/468, accuracy0.859, loss0.358, learning rate 0.0008447 \n",
      "Step: 467/468, accuracy0.867, loss0.393, learning rate 0.0008424 \n",
      "Epoch: 8/10, accuracy0.853, loss0.408, learning rate 0.001\n",
      "--Validation--\n",
      "Validation : Accuracy: 0.856, Loss: 0.395\n",
      "=== Epoch: 9 ===\n",
      "Step: 0/468, accuracy0.836, loss0.382, learning rate 0.0008423 \n",
      "Step: 100/468, accuracy0.609, loss1.136, learning rate 0.0008388 \n",
      "Step: 200/468, accuracy0.680, loss0.770, learning rate 0.0008353 \n",
      "Step: 300/468, accuracy0.766, loss0.599, learning rate 0.0008318 \n",
      "Step: 400/468, accuracy0.867, loss0.349, learning rate 0.0008284 \n",
      "Step: 467/468, accuracy0.852, loss0.379, learning rate 0.0008261 \n",
      "Epoch: 9/10, accuracy0.770, loss0.685, learning rate 0.001\n",
      "--Validation--\n",
      "Validation : Accuracy: 0.854, Loss: 0.404\n",
      "=== Epoch: 10 ===\n",
      "Step: 0/468, accuracy0.844, loss0.528, learning rate 0.0008260 \n",
      "Step: 100/468, accuracy0.828, loss0.456, learning rate 0.0008226 \n",
      "Step: 200/468, accuracy0.852, loss0.391, learning rate 0.0008193 \n",
      "Step: 300/468, accuracy0.805, loss0.475, learning rate 0.0008159 \n",
      "Step: 400/468, accuracy0.867, loss0.418, learning rate 0.0008126 \n",
      "Step: 467/468, accuracy0.867, loss0.421, learning rate 0.0008104 \n",
      "Epoch: 10/10, accuracy0.853, loss0.407, learning rate 0.001\n",
      "--Validation--\n",
      "Validation : Accuracy: 0.863, Loss: 0.394\n",
      "Took 79.1686110496521\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "mlflow.set_experiment(experiment_name='MNIST Fashion reduced conv')\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# my_model.train(X_chns, y, epochs=1, batch_size=8, log_freq=8, validation=(X_chns_test, y_test))\n",
    "my_model.train(X_chns, y, epochs=10, batch_size=128, log_freq=100, validation=(X_chns_test, y_test))\n",
    "\n",
    "t_d0 = time.time() - t0\n",
    "print('Took {}'.format(t_d0))\n",
    "\n",
    "# with mlflow.start_run():\n",
    "#     my_model.train(X_chns, y, epochs=10, batch_size=128, log_freq=100, validation=(X_chns_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the cnn-model with the test-set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation : Accuracy: 0.863, Loss: 0.394\n"
     ]
    }
   ],
   "source": [
    "my_model.evaluate(X_chns_test, y_test, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x504 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(7.00, 7.00), ncols=2, nrows=2)\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.imshow(c[0, 0, :, :], cmap=cm.gray)\n",
    "ax[0, 0].imshow(X_chns[int(np.random.randint(0, 200)), 0, :, :], cmap=cm.gray)\n",
    "ax[0, 1].imshow(X_chns[123, 0, :, :], cmap=cm.gray)\n",
    "# ax[1, 0].imshow(pool1.dinputs[0, 0, :, :], cmap=cm.gray)\n",
    "# ax[1, 1].imshow(conv1.outputs[0, 1, :, :], cmap=cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retreive org. data and flatten for ffnn model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(v):\n",
    "    return v.reshape(v.shape[0], -1)\n",
    "\n",
    "X_flat = vectorize(X)\n",
    "X_flat_test = vectorize(X_test)\n",
    "\n",
    "# print_info(X)\n",
    "# print_info(X_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trucate for ffnn model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truncate to fewer images for integration and timing testing.\n",
    "tval = 9984 # 200, 59968, 9984, 1024, 2048\n",
    "X_flat = X_flat[:tval, :]\n",
    "X_flat_test = X_flat_test[:tval, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling between -1 and 1 - ffnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_img(v):\n",
    "    return (v - 127.5) /127.5\n",
    "\n",
    "X_flat = scale_img(X_flat)\n",
    "X_flat_test = scale_img(X_flat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle training data - ffnn model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = np.array(range(X_flat.shape[0]))\n",
    "np.random.shuffle(keys)\n",
    "X_flat = X_flat[keys]\n",
    "y_flat = y_flat[keys]\n",
    "\n",
    "# print_info(X)\n",
    "# print_info(X_flat)\n",
    "# print_info(y_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a sequence for ffnn model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cce_loss = CategoricalCrossEntropyLoss()\n",
    "optimizer = Adam(decay=5e-5)\n",
    "\n",
    "naive_model = model.Model(optimizer, cce_loss)\n",
    "\n",
    "naive_model.set_sequence([\n",
    "                LinearLayer(X_flat.shape[1], 128),\n",
    "                ReLU(),\n",
    "                Dropout(0.5),\n",
    "                LinearLayer(128, 128),\n",
    "                ReLU(),\n",
    "                LinearLayer(128, 10),\n",
    "                Softmax()\n",
    "            ])\n",
    "\n",
    "# Setting the model save path:\n",
    "path1 = '/Users/petermagnusson/VisualStudioCodeProjects/saved_models/model0'\n",
    "naive_model.set_save_config(model_name='ffnn_0', save_path=path1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with the ffnn model, optional monitoring with MLflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch: 1 ===\n",
      "Step: 0/469, accuracy0.086, loss3.606, learning rate 0.0010000 \n",
      "Step: 100/469, accuracy0.750, loss0.704, learning rate 0.0009950 \n",
      "Step: 200/469, accuracy0.758, loss0.575, learning rate 0.0009901 \n",
      "Step: 300/469, accuracy0.781, loss0.550, learning rate 0.0009852 \n",
      "Step: 400/469, accuracy0.781, loss0.538, learning rate 0.0009804 \n",
      "Step: 468/469, accuracy0.771, loss0.604, learning rate 0.0009771 \n",
      "Epoch: 1/10, accuracy0.743, loss0.713, learning rate 0.001\n",
      "--Validation--\n",
      "Validation : Accuracy: 0.826, Loss: 0.478\n",
      "=== Epoch: 2 ===\n",
      "Step: 0/469, accuracy0.789, loss0.516, learning rate 0.0009771 \n",
      "Step: 100/469, accuracy0.812, loss0.483, learning rate 0.0009723 \n",
      "Step: 200/469, accuracy0.789, loss0.468, learning rate 0.0009676 \n",
      "Step: 300/469, accuracy0.789, loss0.532, learning rate 0.0009630 \n",
      "Step: 400/469, accuracy0.820, loss0.421, learning rate 0.0009584 \n",
      "Step: 468/469, accuracy0.792, loss0.592, learning rate 0.0009552 \n",
      "Epoch: 2/10, accuracy0.814, loss0.515, learning rate 0.001\n",
      "--Validation--\n",
      "New best model ... saving\n",
      "Validation : Accuracy: 0.835, Loss: 0.448\n",
      "=== Epoch: 3 ===\n",
      "Step: 0/469, accuracy0.812, loss0.483, learning rate 0.0009552 \n",
      "Step: 100/469, accuracy0.844, loss0.390, learning rate 0.0009507 \n",
      "Step: 200/469, accuracy0.844, loss0.420, learning rate 0.0009462 \n",
      "Step: 300/469, accuracy0.836, loss0.421, learning rate 0.0009417 \n",
      "Step: 400/469, accuracy0.836, loss0.363, learning rate 0.0009373 \n",
      "Step: 468/469, accuracy0.792, loss0.549, learning rate 0.0009343 \n",
      "Epoch: 3/10, accuracy0.827, loss0.476, learning rate 0.001\n",
      "--Validation--\n",
      "New best model ... saving\n",
      "Validation : Accuracy: 0.835, Loss: 0.432\n",
      "=== Epoch: 4 ===\n",
      "Step: 0/469, accuracy0.828, loss0.465, learning rate 0.0009343 \n",
      "Step: 100/469, accuracy0.820, loss0.450, learning rate 0.0009299 \n",
      "Step: 200/469, accuracy0.875, loss0.351, learning rate 0.0009256 \n",
      "Step: 300/469, accuracy0.867, loss0.413, learning rate 0.0009214 \n",
      "Step: 400/469, accuracy0.836, loss0.400, learning rate 0.0009171 \n",
      "Step: 468/469, accuracy0.833, loss0.492, learning rate 0.0009143 \n",
      "Epoch: 4/10, accuracy0.837, loss0.453, learning rate 0.001\n",
      "--Validation--\n",
      "New best model ... saving\n",
      "Validation : Accuracy: 0.844, Loss: 0.421\n",
      "=== Epoch: 5 ===\n",
      "Step: 0/469, accuracy0.828, loss0.484, learning rate 0.0009142 \n",
      "Step: 100/469, accuracy0.844, loss0.392, learning rate 0.0009101 \n",
      "Step: 200/469, accuracy0.906, loss0.302, learning rate 0.0009060 \n",
      "Step: 300/469, accuracy0.844, loss0.422, learning rate 0.0009019 \n",
      "Step: 400/469, accuracy0.828, loss0.407, learning rate 0.0008978 \n",
      "Step: 468/469, accuracy0.823, loss0.401, learning rate 0.0008951 \n",
      "Epoch: 5/10, accuracy0.845, loss0.432, learning rate 0.001\n",
      "--Validation--\n",
      "New best model ... saving\n",
      "Validation : Accuracy: 0.846, Loss: 0.407\n",
      "=== Epoch: 6 ===\n",
      "Step: 0/469, accuracy0.820, loss0.474, learning rate 0.0008951 \n",
      "Step: 100/469, accuracy0.883, loss0.364, learning rate 0.0008911 \n",
      "Step: 200/469, accuracy0.922, loss0.305, learning rate 0.0008871 \n",
      "Step: 300/469, accuracy0.844, loss0.401, learning rate 0.0008832 \n",
      "Step: 400/469, accuracy0.898, loss0.306, learning rate 0.0008793 \n",
      "Step: 468/469, accuracy0.812, loss0.462, learning rate 0.0008767 \n",
      "Epoch: 6/10, accuracy0.847, loss0.418, learning rate 0.001\n",
      "--Validation--\n",
      "New best model ... saving\n",
      "Validation : Accuracy: 0.856, Loss: 0.399\n",
      "=== Epoch: 7 ===\n",
      "Step: 0/469, accuracy0.844, loss0.405, learning rate 0.0008767 \n",
      "Step: 100/469, accuracy0.875, loss0.438, learning rate 0.0008728 \n",
      "Step: 200/469, accuracy0.906, loss0.273, learning rate 0.0008690 \n",
      "Step: 300/469, accuracy0.836, loss0.481, learning rate 0.0008653 \n",
      "Step: 400/469, accuracy0.898, loss0.368, learning rate 0.0008615 \n",
      "Step: 468/469, accuracy0.833, loss0.397, learning rate 0.0008590 \n",
      "Epoch: 7/10, accuracy0.853, loss0.408, learning rate 0.001\n",
      "--Validation--\n",
      "New best model ... saving\n",
      "Validation : Accuracy: 0.861, Loss: 0.383\n",
      "=== Epoch: 8 ===\n",
      "Step: 0/469, accuracy0.844, loss0.422, learning rate 0.0008590 \n",
      "Step: 100/469, accuracy0.875, loss0.362, learning rate 0.0008553 \n",
      "Step: 200/469, accuracy0.891, loss0.282, learning rate 0.0008517 \n",
      "Step: 300/469, accuracy0.867, loss0.422, learning rate 0.0008481 \n",
      "Step: 400/469, accuracy0.883, loss0.320, learning rate 0.0008445 \n",
      "Step: 468/469, accuracy0.802, loss0.394, learning rate 0.0008421 \n",
      "Epoch: 8/10, accuracy0.856, loss0.394, learning rate 0.001\n",
      "--Validation--\n",
      "New best model ... saving\n",
      "Validation : Accuracy: 0.862, Loss: 0.378\n",
      "=== Epoch: 9 ===\n",
      "Step: 0/469, accuracy0.844, loss0.394, learning rate 0.0008420 \n",
      "Step: 100/469, accuracy0.883, loss0.376, learning rate 0.0008385 \n",
      "Step: 200/469, accuracy0.891, loss0.310, learning rate 0.0008350 \n",
      "Step: 300/469, accuracy0.883, loss0.402, learning rate 0.0008315 \n",
      "Step: 400/469, accuracy0.898, loss0.291, learning rate 0.0008281 \n",
      "Step: 468/469, accuracy0.854, loss0.337, learning rate 0.0008258 \n",
      "Epoch: 9/10, accuracy0.856, loss0.390, learning rate 0.001\n",
      "--Validation--\n",
      "New best model ... saving\n",
      "Validation : Accuracy: 0.868, Loss: 0.366\n",
      "=== Epoch: 10 ===\n",
      "Step: 0/469, accuracy0.836, loss0.390, learning rate 0.0008257 \n",
      "Step: 100/469, accuracy0.891, loss0.377, learning rate 0.0008223 \n",
      "Step: 200/469, accuracy0.891, loss0.268, learning rate 0.0008190 \n",
      "Step: 300/469, accuracy0.867, loss0.362, learning rate 0.0008156 \n",
      "Step: 400/469, accuracy0.875, loss0.285, learning rate 0.0008123 \n",
      "Step: 468/469, accuracy0.844, loss0.387, learning rate 0.0008101 \n",
      "Epoch: 10/10, accuracy0.859, loss0.380, learning rate 0.001\n",
      "--Validation--\n",
      "Validation : Accuracy: 0.863, Loss: 0.381\n",
      "Took 17.058357000350952\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "mlflow.set_experiment(experiment_name='Naive Model')\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# naive_model.train(X_flat, y_flat, epochs=1, batch_size=8, log_freq=32, validation=(X_flat_test, y_test))\n",
    "naive_model.train(X_flat, y_flat, epochs=10, batch_size=128, log_freq=100, validation=(X_flat_test, y_test))\n",
    "\n",
    "t_d0 = time.time() - t0\n",
    "print('Took {}'.format(t_d0))\n",
    "\n",
    "# with mlflow.start_run():\n",
    "#     naive_model.train(X_flat, y_flat, epochs=10, batch_size=128, log_freq=100, validation=(X_flat_test, y_test))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d53c06ab4573055b295bcdfb3b25bc2da21e5ae576a05184a9c53fc2168185ab"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('plant-leaf-diseases-identification-CBiGMIHu-py3.8': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
